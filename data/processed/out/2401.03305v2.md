1

## Leveraging IS and TC: Optimal order execution subject to reference strategies

Xue Cheng 1 , Peng Guo 1 , and Tai-Ho Wang 2

LMEQF, Department of Financial Mathematics, School of Mathematical Sciences, Peking University, Beijing 100871, China. 2

Department of Mathematics, Baruch College, CUNY, 1 Bernard Baruch Way, New York, NY 10010, USA

March 5, 2025

## Abstract

The paper addresses the problem of meta order execution from a broker-dealer's point of view in Almgren-Chriss model under execution risk. A broker-dealer agency is authorized to execute an order of trading on some client's behalf. The strategies that the agent is allowed to deploy is subject to a benchmark, referred to as the reference strategy, regulated by the client. We formulate the broker's problem as a utility maximization problem in which the broker seeks to maximize his utility of excess profit-and-loss at the execution horizon, of which optimal feedback strategies are obtained in closed form. In the absence of execution risk, the optimal strategies subject to reference strategies are deterministic. We establish an affine structure among the trading trajectories under optimal strategies subject to general reference strategies using implementation shortfall (IS) and target close (TC) orders as basis. Furthermore, an approximation theorem is proposed to show that with small error, general reference strategies can be approximated by piece-wise constant ones, of which the optimal strategy is piece-wise linear combination between IS and TC orders. We conclude the paper with numerical experiments illustrating the trading trajectories as well as histograms of terminal wealth and utility at investment horizon under optimal strategies versus those under TWAP strategies.

Keywords: Optimal execution; Price impact; Execution risk; Utility maximization; Reference strategy; Affine structure; Implementation shortfall order; Target close order

## Contents

| 1   | Introduction                            |   3 |
|-----|-----------------------------------------|-----|
| 2   | Model setup                             |   5 |
| 2.1 | Price impact model .                    |   5 |
| 2.2 | Reference strategy                      |   6 |
| 3   | Optimal execution as utility maximizing |   7 |
|     | Optimal execution with risk aversion    |   7 |

| 4 Zero execution risk   | 4 Zero execution risk   | 4 Zero execution risk                                             |   10 |
|-------------------------|-------------------------|-------------------------------------------------------------------|------|
|                         | 4.1                     | General reference strategy                                        |   11 |
|                         | 4.2                     | Implementation shortfall (IS) order and target close (TC) order . |   12 |
|                         | 4.3                     | Endpoints-only reference strategy .                               |   14 |
|                         | 4.4                     | Piece-wise constant reference strategy                            |   16 |
| 5                       | Numerical examples      | Numerical examples                                                |   18 |
|                         | 5.1                     | Sample trading trajectories                                       |   18 |
|                         | 5.2                     | Performance analysis and stress test                              |   22 |
| 6                       | Conclusion              | Conclusion                                                        |   25 |
|                         | A Appendix              | A Appendix                                                        |   25 |

## 1 Introduction

In the financial industry, large position holders such as pension funds or investment banks for various reasons are required to trade in or trade out from their current position to an updated target, possibly subject to a given execution horizon which may vary from days to weeks. The net holdings to be adjusted between the current and the target positions are usually too large to be simply dumped to the market without a priori deliberately assessing the trade's market impact. Untamed price impact by trading may result in significant transaction cost, potentially turned into a substantial loss. Such an execution risk requires to be properly managed and controlled; otherwise it would eventually influence the position holder's overall profit and loss (P&amp;L). A common practice is to delegate the execution to the firm's order execution department or outsource to a broker-dealer agency.

The large position holders, while delegating their tasks to an agency for execution, may have in mind their own preferred strategies or benchmarks that they would like the delegated agent to closely track along. For instance, implementation shortfall (IS) orders [1] are frequently employed by managers for the purpose of short-term alpha pursuit. IS orders are constructed with a pre-trade benchmark price in mind, aiming at executing orders at an average price that remains relatively close to the market price at the beginning of the trade. Managers can often use arrival prices to help measure total trading costs: the closer the execution price is to the arrival price, the lower the associated costs (see CFA-level-II [2]). On the contrary, target close (TC) orders [3], often deployed by index-fund managers for the purpose of minimizing fund risk and tracking error, are formulated with a post-trade benchmark price in order to secure a price in average that remains relatively close to the closing price. This is often important for mutual fund managers who manage funds that only calculate NAV once daily at closing. Volume weighted average price (VWAP) and Time weighted average price (TWAP) strategies are benchmarks specified for trading sequences with constant trading rate in wall clock time (TWAP) and in volume time (VWAP) respectively. These algorithmic trading strategies are examples of benchmarks that may be imposed as trading constraints to the agent who is missioned to trade in or trade out the position. We shall delve into this type of order execution problems subject to a pre-specified benchmark strategy, which we refer to as the reference strategy (RS for short), as a stochastic control problem and determine their corresponding optimal strategies in feedback form.

The pioneering works in [4], [1], [5] and [6] are among the first to deal with the problem of order execution under price impact. Since its introduction to the order execution problem, numerous progresses and extensions on the classical Almgren-Chriss framework have been made extensively. For instance, [7] and [8] introduced the notion of transient impact to account for the dissipation of price impacts from the past trades. [9] discusses the objective in the optimization problem, while [10] extends the classical mean-variance framework first considered in [4] to encompass general risk measures as penalty for risk aversion. [11], [12], [13] solve the optimal execution problem in relation to a VWAP benchmark, while [14] asserts the use of the arrival price as a benchmark within the Almgren-Chriss framework. In fact, the arrival price, also known as 'pre-trade benchmark', appears to be the most commonly used benchmark in academic papers. The closing price is the value of a security at its last transaction during a trading session [3] [15]. Average price benchmarks may also appear in accelerated share repurchase (ASR) contracts [16][17], which can be regarded as optimal execution problems with optimal stopping. Above all, [18] introduces the concept of execution risk, that

pre-scheduled orders may not be fully executed, of which the empirical evidence is confirmed by [19] that the inventory processes of traders invariably contain a Brownian motion term, which contradicts the common assumption adopted in most optimal execution models that the inventory process is absolute continuous. Another perspective on introducing the noise term into the inventory process is that when a centralized trading desk aggregates order flows within a financial institution, stochastic order flow arises [20] [21]. The aforementioned papers are by no means meant for an exhausting list in literature on this line of active research.

In the current paper, we consider the order execution problem from a broker-dealer's point of view. Assume that a broker is delegated to reallocate a client's holdings of a certain stock under the Almgren-Chriss model with execution risk. The broker is regulated by his client to track a benchmark strategy, i.e., the reference strategy, to the client's preference. The broker's incentive of executing client's order in this circumstance is to maximize his own expected P&amp;L excess to that of the reference strategy, marked-to-market. To account for risk aversion, we recast the broker's order execution problem as a utility maximization problem and, in certain cases, are able to solve the problem in closed form. In particular, when execution risk vanishes, or becomes negligible, we show that there exists an 'affine structure' among the optimal strategies induced from various reference strategies. This algebraic structure is supposed to help the broker for concocting and understanding optimal strategies subject to client's general reference strategies. We argue that the framework is highly versatile in the sense that it encompasses commonly deployed execution strategies such as IS, TC as well as TWAP and VWAP orders as special cases for benchmarking. As per the algebraic structure, it follows that, for any given continuous reference strategy which can be approximated by a piece-wise constant function, we show that its corresponding optimal strategy can also be approximated by those induced from the piece-wise constant strategies.

The rest of the paper is organized as follows. In Section 2, we lay out the price impact model of AlmgrenChriss under execution risk and incorporate reference strategies into the problem of order execution. Section 3 presents the optimal feedback control of the order execution problem in Theorem 1 as one of the main results in the paper. Section 4 focuses and provides detailed discussions on the optimal strategies when execution risk vanishes. Reference strategies and their associated optimal strategies considered in Section 4 include IS and TC orders as well as piece-wise constant strategies. The emphasis is put on an 'affine structure' among the trading trajectories induced by general reference strategies using unit IS and unit TC orders as a basis. Numerical examples illustrating the trading trajectories and the performance analysis under the optimal and TWAP strategies are shown and discussed in Section 5. For the sake of smooth reading, technical proofs of all the theorems, propositions and lemmas are postponed and collected till the end of the paper as an appendix in Section A.

Throughout the paper, (Ω , F , P ) denotes a complete probability space equipped with a filtration describing the information structure F := {F t } t ∈ [0 ,T ] , where t is the time variable and T &gt; 0 the fixed finite liquidation horizon. Let { W t , Z t } t ∈ [0 ,T ] be a two-dimensional Brownian motion with constant correlation ρ defined on (Ω , F , P ) . The filtration F is generated by the trajectories of the above Brownian motion, completed with all P -null measure sets of F .

## 2 Model setup

## 2.1 Price impact model

Assume a broker is delegated to reallocate a client's holdings of a certain stock from x 0 shares to A shares within a given horizon T . Let x t be the number of shares the broker holds at time t ∈ [0 , T ] during the reallocation process and ˜ S t the transacted price at time t . The price dynamic is assumed to follow the Almgren-Chriss model [4] [1] [5]. In the Almgren-Chriss framework, the transacted price ˜ S t consists of the fair price S t and a slippage. The fair price S t is driven by the SDE

$$d S _ { t } = \mu d t + \gamma d x _ { t } + \sigma d W _ { t } ,$$

$$S _ { t } = S _ { 0 } + \mu t + \gamma ( x _ { t } - x _ { 0 } ) + \sigma W _ { t } ,$$

where µt describes the tendency of the stock and ( W t ) t ∈ [0 ,T ] is a standard Brownian motion. The term γ ( x t -x 0 ) , for γ ≥ 0 , is usually referred to as the permanent impact . Penalized by a price slippage, the transacted price is thus given by

$$S _ { t } = S _ { t } - \eta v _ { t } ,$$

where v t denotes the broker's intended trading rate at the instant t . The slippage -ηv t , for η ≥ 0 , is also referred to as the temporary impact . We remark that in the original setting of Almgren-Chriss and its extensions, the trading rate v t plays a dual role. On the one hand, it serves as the realized trading rate per the relationship v t = -˙ x t between x t and v t . On the other hand, it is regarded as the control variable in the problem of optimal execution. These two seemingly distinct roles coincide if all the scheduled orders are guaranteed fully executed. However, in reality it is well noticed among practitioners that, while executing a sequence of pre-scheduled orders, the orders in the sequence may not be fully executed, resulting in an uncontrollable realized order flow. This introduces an additional risk to the order execution problem, the execution risk . To account for this uncertainty, we introduce a noise component driven by a correlated Brownian motion Z t into the dynamic of the position x t as

$$d x _ { t } = - v _ { t } d t + m ( v _ { t } ) d Z _ { t } .$$

The diffusion term m ( v ) characterizes the magnitude of execution risk. It is worth to reiterate that in a recent work in [19], the authors showed that the presence of a Brownian component in the broker's inventory during reallocation process is statistically significant. Moreover, because of this execution risk, the broker is no longer guaranteed to achieve his intended position at the terminal time T , which gives rise to an additional opportunity cost. As a result, the broker is obligated to take a final block trade at time T at a worse price. Overall, the realised P&amp;L at the horizon T is given by

$$\Pi \colon = ( x _ { T } - A ) S _ { T } - \beta ( x _ { T } - A ) ^ { 2 } + \int _ { 0 } ^ { T } \left ( - \tilde { S } _ { t } \right ) d x _ { t } ,$$

or equivalently,

where the term β ( x T -A ) 2 , for β ≥ 0 , penalizes the discrepency from a final block trade.

The following proposition shows that the P&amp;L can be written as an Itô process.

Proposition 1. The realised P&amp;L can be rewritten as

$$\Pi = & ( x _ { 0 } - A ) S _ { 0 } - \beta ( x _ { T } - A ) ^ { 2 } + \int _ { 0 } ^ { T } \left ( \mu ( x _ { t } - A ) + \rho \sigma m ( v _ { t } ) - \eta v _ { t } ^ { 2 } - \gamma v _ { t } ( x _ { t } - A ) \right ) d t \\ & + \int _ { 0 } ^ { T } \sigma ( x _ { t } - A ) d W _ { t } + \int _ { 0 } ^ { T } ( \eta v _ { t } + \gamma ( x _ { t } - A ) ) m ( v _ { t } ) d Z _ { t } .$$

## 2.2 Reference strategy

A common practice in order execution brokerage is that clients may come forward to brokers with their own preferred strategies for benchmarking. These benchmark strategies can be either strategies suggested by elite investors or commonly used ones such as TWAP strategies. We shall refer to these pre-specified benchmark strategies as reference strategies . We consider the reference strategies that can be represented by a deterministic function ( R t ) t ∈ [0 ,T ] with R 0 ≡ x 0 and R T ≡ A hereafter. Moreover, we assume that R t is a differentiable a.e. function. The broker's incentive of executing client's order is thus to maximize his own expected P&amp;L excess to that of the reference strategy, marked-to-market. Specifically, by disregarding the price impact and slippages incurred from order execution, the stock price S 0 t reads

$$S _ { t } ^ { 0 } = S _ { 0 } + \mu t + \sigma W _ { t } .$$

The marked-to-market P&amp;L Π R for the reference strategy R is evaluated as

$$\Pi ^ { R } & \coloneqq \int _ { 0 } ^ { T } \left ( - S _ { t } ^ { 0 } \right ) d R _ { t } \\ & = - \left ( S _ { t } ^ { 0 } R _ { t } \right ) \left | _ { 0 } ^ { T } + \int _ { 0 } ^ { T } R _ { t } ( \rho d t + \sigma d W _ { t } ) \\ & = - \, . A S _ { T } ^ { 0 } + x _ { 0 } S _ { 0 } + \int _ { 0 } ^ { T } \mu R _ { t } d t + \int _ { 0 } ^ { T } \sigma R _ { t } d W _ { t } \\ & = ( x _ { 0 } - A ) S _ { 0 } + \int _ { 0 } ^ { T } \mu ( R _ { t } - A ) d t + \int _ { 0 } ^ { T } \sigma ( R _ { t } - A ) d W _ { t } .$$

Hence, the broker's excess P&amp;L ˜ Π , defined by the difference between Π and Π R , is given by

$$\tilde { \Pi } \coloneqq & \Pi - \Pi ^ { R } \\ & = - \beta ( x _ { T } - A ) ^ { 2 } + \int _ { 0 } ^ { T } \left ( \mu ( x _ { t } - R _ { t } ) + \rho \sigma m ( v _ { t } ) - \eta v _ { t } ^ { 2 } - \gamma v _ { t } ( x _ { t } - A ) \right ) d t \\ & \quad + \int _ { 0 } ^ { T } \sigma ( x _ { t } - R _ { t } ) d W _ { t } + \int _ { 0 } ^ { T } ( \eta v _ { t } + \gamma ( x _ { t } - A ) ) m ( v _ { t } ) d Z _ { t } .$$

The broker's goal is thus to maximize his expected excess P&amp;L in a risk aversion manner which we recast as a utility maximization problem in the section that follows.

## 3 Optimal execution as utility maximizing

In this section, we recast the problem of order execution as a utility maximization problem as follows. Recall that (Ω , F , P ) denotes a complete probability space equipped with a filtration ( F t ) t ≥ 0 satisfying the usual conditions. We assume that all random variables and stochastic processes are defined on (Ω , F , ( F t ) t ≥ 0 , P ) . The set of all real-valued progressively measurable processes are denote by M , while the collection of admissible controls A is set as

$$\mathcal { A } \colon = \left \{ v \in \mathcal { M } \colon \int _ { 0 } ^ { T } \mathbb { E } [ v _ { t } ^ { 2 } ] d t < \infty \right \} .$$

to meet the assumptions given in [22] and [23], which assure the solvability of both the risk-neutral problem and the risk-aversion one. The broker's problem is to determine an optimal admissible strategy v ∗ that maximizes his expected exponential utility at the horizon T , i.e.,

$$\sup _ { v \in \mathcal { A } } \mathbb { E } \left [ u \left ( \tilde { \mathbf I } \right ) \right ] ,$$

where the utility function u ( x ) := 1 θ (1 -e -θx ) , θ &gt; 0 represents the broker's preference following CARA (Constant Absolute Risk Aversion) preference and θ &gt; 0 is the risk-aversion parameter. Note that as θ ↓ 0 , the utility function u ( x ) = lim θ ↓ 0 1 θ (1 -e -θx ) = x reflects a risk-neutral preference. When the utility function is selected as u ( x ) = x , we solve the stochastic control problem and give the close form of the value function E [ ˜ Π ] ∣ ∣ ∣ ∣ v = v ∗∗ = sup v ∈A E [ ˜ Π ] &lt; ∞ , where v ∗∗ ∈ A is the optimal feedback control in the risk-neutral case, see in Appendix A.2. Moreover, when u ( x ) = 1 θ (1 -e -θx ) , u ′ ( x ) = e -θx &gt; 0 , u ′′ ( x ) = -θe -θx &lt; 0 , so u ( · ) is a increasing concave function. For any admissible control ˜ v , by Jensen's inequality,

$$\mathbb { E } \left [ u \left ( \tilde { \Pi } \right ) \right ] \Big | _ { v = \tilde { v } } \leq u \left ( \mathbb { E } \left [ \tilde { \Pi } \right ] \Big | _ { v = \tilde { v } ^ { * } } \right ) \leq u \left ( \mathbb { E } \left [ \tilde { \Pi } \right ] \Big | _ { v = v ^ { * } } \right ) < \infty ,$$

which shows the finiteness of the utility maximizing problem. In the following, we solve the utility maximization problem (2) and present solutions in closed form in the cases where the execution risk m ( v ) is either a constant or zero. The case of zero execution risk is postponed and will be discussed in more details in Section 4.

## 3.1 Optimal execution with risk aversion

When the execution risk is constant, i.e., m ( v ) ≡ m 0 for some fixed constant m 0 , the utility maximizing problem reduces to the following Stochastic Linear Exponential Quadratic (SLEQ) control problem [23] [24]

$$\begin{cases} \sup _ { v \in A } \left [ u ( \tilde { H } ) \right ] = & \sup _ { v \in A } \left [ \frac { 1 } { \theta } \left ( 1 - \exp \left ( \theta \beta ( x _ { T } - A ) ^ { 2 } - \int _ { 0 } ^ { T } \theta \left ( \mu ( x _ { T } - R _ { T } ) + \rho \sigma m _ { 0 } - \mu v _ { t } ^ { 2 } - \gamma v _ { t } ( x _ { T } - A ) \right ) d t \\ & - \int _ { 0 } ^ { T } \theta \sigma ( x _ { T } - R _ { T } ) d W _ { T } - \int _ { 0 } ^ { T } \theta ( \mu v _ { t } + \gamma ( x _ { T } - A ) m _ { 0 } d Z _ { T } ) \right ) \right ] , \\ & s . t . \ x _ { T } = x _ { 0 } - \int _ { 0 } ^ { T } v _ { s d s } + m _ { 0 } z _ { T } . \end{cases}$$

Define the value function of the problem by

$$V ( t , x ) \coloneqq & \sup _ { v \in A } \left [ \left \lceil \frac { 1 } { \theta } \left ( 1 - \exp \left ( \theta \beta ( x _ { T } - A ) ^ { 2 } - \int _ { t } ^ { T } \theta \left ( \mu ( x _ { s } - R _ { s } ) + \rho \sigma m _ { 0 } - \eta v _ { s } ^ { 2 } - \gamma v _ { s } ( x _ { s } - A ) \right ) d s \\ & - \int _ { t } ^ { T } \theta \sigma ( x _ { s } - R _ { s } ) d W _ { s } - \int _ { t } ^ { T } \theta ( \eta v _ { s } + \gamma ( x _ { s } - A ) ) m _ { 0 } d Z _ { s } \right ) \right \rceil x _ { t } = x \right ] ,$$

where A t := { v is progressively measurable in [ t, T ] and ∫ T t E [ v 2 s ]d s &lt; ∞ } . The optimal feedback control can be obtained in closed form. We summarize the result in the following theorem.

Theorem 1. The value function (4) of the utility maximization problem has the closed form expression

$$V ( t , x ) = \frac { 1 } { \theta } \left ( 1 - \exp \left \{ \left ( b _ { 2 } ( t ) + \frac { \theta \gamma } { 2 } \right ) ( x - A ) ^ { 2 } + b _ { 1 } ( t ) ( x - A ) + b _ { 0 } ( t ) \right \} \right ) .$$

where the parameters H , l 1 , and l 3 are given by

$$\begin{cases} \, H = \theta \eta + \frac { 1 } { 2 } \theta ^ { 2 } \eta ^ { 2 } m _ { 0 } ^ { 2 } , \\ \, l _ { 3 } = \frac { 1 } { 2 } m _ { 0 } \eta \theta ^ { 2 } \rho \sigma , \\ \, l _ { 1 } = \frac { \theta ^ { 2 } \sigma ^ { 2 } } { 2 } H . \end{cases}$$

The time dependent function b 2 is given in closed form by

$$b _ { 2 } ( t ) \coloneqq \sqrt { l _ { 1 } } \coth \left ( A _ { 0 } + \frac { \sqrt { l _ { 1 } } } { H } ( T - t ) \right ) - l _ { 3 } , \quad \text {where} \ \ A _ { 0 } \coloneqq \coth ^ { - 1 } \left ( \frac { l _ { 3 } + \frac { \theta } { 2 } ( 2 \beta - \gamma ) } { \sqrt { l _ { 1 } } } \right ) ,$$

b 1 is the solution to the following terminal value problem

$$b _ { 1 } ^ { \prime } ( t ) = \theta \mu + \frac { 1 } { H } b _ { 1 } ( t ) \left ( b _ { 2 } ( t ) + l _ { 3 } \right ) + \frac { \eta \theta ^ { 2 } \sigma } { H } ( R _ { t } - A ) \left ( \theta \sigma + \frac { 1 } { 2 } m _ { 0 } ^ { 2 } \theta _ { 0 } ^ { 2 } \eta \sigma ( 1 - \rho ^ { 2 } ) - \rho m _ { 0 } b _ { 2 } ( t ) \right ) , \ b _ { 1 } ( T ) = 0 ,$$

and

$$b _ { 0 } ( t ) \colon = \int _ { t } ^ { T } \left [ \frac { l _ { 1 } - l _ { 3 } ^ { 2 } } { H } ( R _ { s } - A ) ^ { 2 } + \left ( \theta \mu + \frac { l _ { 3 } } { H } b _ { 1 } \right ) ( R _ { s ^ { - } } - A ) + \left ( - \frac { b _ { 1 } ^ { 2 } } { 4 H } + m _ { 0 } ^ { 2 } \left ( b _ { 2 } + \frac { \theta \gamma } { 2 } \right ) - \rho m _ { 0 } \theta \sigma \right ) \right ] d s .$$

Moreover, the optimal feedback control v ∗ ∈ A of the utility maximization problem (2) is given by

$$v _ { t } ^ { * } = \frac { ( 1 + \theta \eta m _ { 0 } ^ { 2 } ) _ { t } ^ { 2 } } { H } \cdot ( x _ { t } - A ) + \frac { 1 + \theta \eta m _ { 0 } ^ { 2 } } { 2 H } \cdot b _ { 1 } ( t ) + \frac { l _ { 3 } } { H } \cdot ( R _ { t } - x _ { t } ) ,$$

It's worth mentioning that this theorem does not contain much mathematical breakthrough, instead, we regard it as a fundamental result to introduce valuable results in section 4, where the affine structure is what we find the most interesting.

Remark 1. The optimal feedback control v ∗ t in (5) consists of three parts:

- The first part (1+ θηm 2 0 ) b 2 H · ( x t -A ) has the same sign as x t -A . Without loss of generality, we assume that x 0 &gt; A , when x t ≥ A , which implies the reallocation process has not finished, so the broker should

continue to sell the stock. Conversely, when x t &lt; A , which implies the strategy is over-shooting, so the broker should buy some shares of the stock back.

- The second part 1+ θηm 2 0 2 H · b 1 , which is a pre-specified deterministic function in time t , does not depend on the state variable x t .
- The third part l 3 H · ( R t -x t ) has the same sign as ρ ( R t -x t ) , where ρ is the correlation between the stock price process and the execution risk. The discussions in [25] state the fact that the sign of ρ depends on the order type adopted by the trader due to adverse selection: when the trader uses market orders, the correlation ρ is negative while ρ is positive whenever trading with limit orders. In this paper, we regard ρ as a market parameter reflecting whether the market is trader-friendly or not.
- -When ρ ≥ 0 , the stock price and execution risk tend to increase or decrease together: when the stock price increases, execution risk makes traders buy more or sell less than the amount they submit, which is benefit to the traders; when the stock price decreases, execution risk forces traders to buy less or sell more, which is also benefit to the traders. In such trader-friendly market, like the figure (1a), the broker should keep away from the reference strategy R t because an overly conservative strategy is not necessary.
- -On the contrary, ρ &lt; 0 implies a trader-harmful market: when the stock price increases, execution risk makes traders buy less or sell more than the amount they submit, which is harm to the traders; when the stock price decreases, execution risk forces traders to buy more or sell less, which is also harm to the traders. In such trader-harmful market, like the figure (1b), the broker should keep close to the reference strategy R t to attain lower risk.

Figure 1: Market parameter ρ

other

The diagram consists of two figures, labeled as (a) and (b). In figure (a), there is a straight line segment labeled as x. On this line segment, there are two points labeled as A and B. A line segment is drawn from point A to a point labeled as C, forming a right angle with the line segment x. In figure (b), there is a straight line segment labeled as x. On this line segment, there are two points labeled as A and B. A line segment is drawn from point A to a point labeled as C, forming a right angle with the line segment x.

![Image](C:\Users\KITES\Desktop\Projekt2025\data\OpenRAGBench\out\2401.03305v2_artifacts\image_000000_d741fe3abc50ba8b101f99984b7f56633e5cd054dd136ca3c292cb28539656a0.png)

Remark 2. By applying the optimal strategy (5), one obtains the optimal liquidation trajectory x ∗ t as follows. For simplicity, take the parameters A = ρ = 0 , R t ≡ 0 and µ = 0 , x ∗ t satisfies the SDE

$$d x _ { t } ^ { * } = - \left ( \frac { ( 1 + \theta \eta m _ { 0 } ^ { 2 } ) b _ { 2 } } { H } x _ { t } ^ { * } + \frac { ( 1 + \theta \eta m _ { 0 } ^ { 2 } ) b _ { 1 } } { 2 H } \right ) \, \mathrm d t + m _ { 0 } \mathrm d Z _ { t } ,$$

as β → + ∞ , x ∗ t has the limit

$$x _ { t } ^ { * * } = \left ( \frac { \sinh \left ( \frac { \sqrt { l _ { 1 } } } { H } ( T - t ) \right ) } { \sinh \left ( \frac { \sqrt { l _ { 1 } } } { H } T \right ) } \right ) ^ { \frac { 2 H } { \theta \eta } - 1 } x _ { 0 } + m _ { 0 } \int _ { 0 } ^ { t } \left ( \frac { \sinh \left ( \frac { \sqrt { l _ { 1 } } } { H } ( T - t ) \right ) } { \sinh \left ( \frac { \sqrt { l _ { 1 } } } { H } ( T - s ) \right ) } \right ) ^ { \frac { 2 H } { \theta \eta } - 1 } d Z _ { s } .$$

Furthermore, when m 0 → 0 , H → θη , the limit of the expression above is

$$\lim _ { m _ { 0 } \to 0 } x _ { t } ^ { * * } = \frac { \sinh ( \kappa ( T - t ) ) } { \sinh ( \kappa T ) } x _ { 0 } ,$$

where κ = √ θσ 2 2 η . It recovers the classical implementation shortfall (IS) strategy (see in section 4.2), which implies the fact that our strategy can be regarded as a version of adaptive IS strategy. Furthermore, we may find that

$$\lim _ { m _ { 0 } \to 0 } \frac { x _ { t } ^ { * * } - \frac { \sinh ( \kappa ( T - t ) ) } { \sinh ( \kappa T ) } x _ { 0 } } { m _ { 0 } } = \int _ { 0 } ^ { t } \frac { \sinh \left ( \kappa ( T - t ) \right ) } { \sinh \left ( \kappa ( T - s ) \right ) } d Z _ { s } ,$$

which is an Ornstein-Uhlenbeck bridge [26]. Therefore, when m 0 is small, one may find an approximation to the optimal strategy

$$x _ { t } ^ { * * } \approx \frac { \sinh ( \kappa ( T - t ) ) } { \sinh ( \kappa T ) } x _ { 0 } + m _ { 0 } \int _ { 0 } ^ { t } \frac { \sinh \left ( \kappa ( T - t ) \right ) } { \sinh \left ( \kappa ( T - s ) \right ) } d Z _ { s } ,$$

which is a classical IS strategy plus an Ornstein-Uhlenbeck bridge, which reduces the strategy's inventory risk. Figure (2) shows the inventory risk of the optimal strategy and the classical IS strategy, which shows the fact that our optimal strategy has lower inventory risk than the classical IS strategy, especially at the end of the trading process.

Figure 2: Inventory risk of the optimal strategy and the classical IS strategy

line chart

The image you've provided is a line graph with two lines, one labeled "Almgren-Chriss" and the other "Optimal". The "Almgren-Chriss" line starts at the origin (0,0) and increases linearly, reaching the top right corner of the graph. The "Optimal" line starts at (0.2, 0.2) and decreases linearly, also reaching the bottom left corner of the graph. The graph is set against a light gray background.

![Image](C:\Users\KITES\Desktop\Projekt2025\data\OpenRAGBench\out\2401.03305v2_artifacts\image_000001_af20e34e77e45e19240dc271a5c58471da60864335ff34830d4e09dd7cb274eb.png)

To summary the section, it should be emphasized that despite the optimal feedback control behaves linearly in the states carries a certain meaning which we discuss in Remark 1, however, the case which we care most is where the execution risk does not exist, which is a limit case of Theorem 1, discussed in the next section.

## 4 Zero execution risk

For the purpose of better understanding as well as visualizing the optimal strategy obtained in (5), we present in this section the trading trajectory x t under optimal strategy in the case when m 0 = 0 for various reference strategies. In Section 4.1, we give the optimal strategy for general reference strategies. In Section 4.2, we present two classic trading strategies: IS order and TC order, both widely used in the market, and show that

they are special cases of our model. Next, we consider the case when the reference strategy is an endpointsonly one in Section 4.3, of which the optimal strategy has a heuristic form. Last but not least, piece-wise constant reference strategies are studied in Section 4.4.

Notice that in this case the setting of the problem reduces to that of the Almgren-Chriss but subject to a reference strategy. Furthermore, we shall set the final penalty parameter β → + ∞ , indicating that a final block trade at terminal time T is strictly prohibited.

## 4.1 General reference strategy

For a given generic reference strategy R t , the following theorem shows a representation for the trading trajectory x t under optimal control v ∗ .

Theorem 2. Let m ( v ) ≡ 0 and β → + ∞ . The trajectory x t under the solution to the optimization problem (2) is given by

$$x _ { t } = & \frac { \kappa } { \sinh \kappa T } \int _ { 0 } ^ { T } \left ( R _ { s } \sinh ( \kappa \min ( s , t ) ) \sinh ( \kappa ( T - \max ( s , t ) ) ) \right ) d s \\ & + \left ( x _ { 0 } - \frac { \mu } { \theta \sigma ^ { 2 } } \right ) \cdot \frac { \sinh \kappa ( T - t ) } { \sinh \kappa T } + A + \left ( - A + \frac { \mu } { \theta \sigma ^ { 2 } } \right ) \cdot \frac { \sinh \kappa T - \sinh \kappa t } { \sinh \kappa T } ,$$

with the tuning parameter κ := √ θσ 2 2 η .

A few remarks on the trajectory x t shown in Theorem 2 are in order.

Remark 3. The parameter κ can be regarded as a tuning parameter between the TWAP and the reference strategies if µ = 0 . Specifically, in the limit as κ approaches zero, the optimal strategy converges to the TWAP strategy, i.e., for any t ∈ [0 , T ] , we have

$$\lim _ { \kappa \to 0 } x _ { t } = A + ( x _ { 0 } - A ) \cdot \left ( 1 - \frac { t } { T } \right ) .$$

On the other extreme as κ →∞ , the optimal trajectory converges to the reference strategy R t itself

$$\lim _ { \kappa \rightarrow \infty } x _ { t } = R _ { t }$$

for any t ∈ [0 , T ] .

Remark 4. The optimal trajectory may also be written as an 'affine transformation' as

$$x _ { t } = \frac { \mu } { \theta \sigma ^ { 2 } } + a _ { t } \cdot \frac { \sinh \kappa ( T - t ) } { \sinh \kappa T } + b _ { t } \cdot \frac { \sinh \kappa t } { \sinh \kappa T } ,$$

$$t$$

$$a _ { t } & = x _ { 0 } - \frac { \mu } { \theta \sigma ^ { 2 } } + \int _ { 0 } ^ { t } \kappa R _ { s } \sinh \kappa s d s , \\ b _ { t } & = A - \frac { \mu } { \theta \sigma ^ { 2 } } + \int _ { t } ^ { T } \kappa R _ { s } \sinh \kappa ( T - s ) d s .$$

$$l _ { S } .$$

A more detailed discussion on this affine transformation can be found in Section 4.4.

where

Next, we further specialize the reference strategies and present their corresponding trajectories in the following sections.

## 4.2 Implementation shortfall (IS) order and target close (TC) order

Assume µ = 0 and the broker is asked to take as the reference strategy a block trade of size | A -x 0 | at t = 0 , i.e.,

$$R _ { t } ^ { I S } = \begin{cases} x _ { 0 } , & t = 0 , \\ A , & 0 < t \leq T . \end{cases}$$

The corresponding marked-to-market P&amp;L of the reference strategy R IS is given by

$$\Pi ^ { I S } \coloneqq \int _ { 0 } ^ { T } \left ( - S _ { t } ^ { I S } \right ) d R _ { t } ^ { I S } & = - \left ( x _ { 0 } - A \right ) \cdot \frac { S _ { 0 - } ^ { I S } + S _ { 0 + } ^ { I S } } { 2 } \\ & = - \left ( x _ { 0 } - A \right ) S _ { 0 } + \frac { \gamma } { 2 } ( x _ { 0 } - A ) ^ { 2 } ,$$

which is equivalent to choosing the initial price S 0 as reference price. This model is referred to as an implementation shortfall model in [27], of which the optimal strategy is

$$x _ { t } = A + ( x _ { 0 } - A ) \cdot \text {IS} _ { t } ,$$

$$IS _ { t } \colon = \frac { \sinh \kappa ( T - t ) } { \sinh \kappa T } .$$

We shall refer to the strategy IS t as the unit implementation shortfall (IS) order . Hence, the trajectory in (6) can be interpreted as executing x 0 -A unit IS orders if a broker is missioned to make transition of his position from x 0 to A shares. We remark that, as we will show in Section 4.4, the unit IS orders are used as one of the building blocks for the construction of optimal trajectories for more general reference strategies.

Figure 3: Basic strategies in varying parameter κ .

line chart

The graph shows the relationship between the number of hours studied and the final exam score.

![Image](C:\Users\KITES\Desktop\Projekt2025\data\OpenRAGBench\out\2401.03305v2_artifacts\image_000002_a53f0e1665b766b1a458bb0660f2cb375265336d1541d0794be173f81da1712d.png)

Figure (3a) shows examples of the unit implementation shortfall orders under various values of κ . Notice that, since κ = √ θσ 2 2 η , as θ, σ increase or η decreases, thus κ increases, the trajectories suggest the broker where

trade faster at the beginning and more slowly for the rest of the reallocation process. Indeed, the larger the κ , the faster the trading at the beginning. The financial rationale is as follows. Recall that θ is the coefficient of relative risk aversion for the utility function and σ is the volatility of stock price. Hence, if either of the parameters increases, the broker is more concerned with the price risk than the execution risk, he tends toward trading faster at the beginning and more slowly thereafter. Also, since η is the coefficient of slippage, as it decreases, the slippage decreases as well, resulting in lower cost from faster transactions. Therefore, again to mitigate the concern of price risk during reallocation process, the broker should also trade faster at the beginning as well.

Finally, we remark that, as κ → 0 , the unit IS order (7) converges to the TWAP (Time-Weight-AveragePrice) strategy: for any t ∈ [0 , T ] ,

$$\lim _ { \kappa \to 0 } I S _ { t } = \lim _ { \kappa \to 0 } \frac { \sinh \kappa ( T - t ) } { \sinh \kappa T } = \frac { T - t } { T } .$$

On the flip side, as κ → + ∞ , the optimal trajectory (7) converges to a block trade at time 0 :

$$\lim _ { \kappa \to \infty } \text {IS} _ { t } = \lim _ { \kappa \to \infty } \frac { \sinh \kappa ( T - t ) } { \sinh \kappa T } = \lim _ { \kappa \to \infty } e ^ { - \kappa t } \cdot \frac { 1 - e ^ { - 2 \kappa ( T - t ) } } { 1 - e ^ { - 2 \kappa T } } = \begin{cases} 1 , t = 0 , \\ 0 , 0 < t \leq T . \end{cases}$$

Assume again that µ = 0 . Here the broker is given as the reference strategy to take only a block trade of size | A -x 0 | at terminal time T . That is,

$$R _ { t } ^ { T C } = \begin{cases} x _ { 0 } , \ 0 \leq t < T , \\ A , t = T . \end{cases}$$

The marked-to-market P&amp;L Π TC for this reference strategy is given by

$$\Pi ^ { T C } = \int _ { 0 } ^ { T } \left ( - S _ { t } ^ { T C } \right ) d R _ { t } ^ { T C } = & - ( x _ { 0 } - A ) \cdot \frac { S _ { T - } ^ { T C } - S _ { T + } ^ { T C } } { 2 } \\ = & - ( x _ { 0 } - A ) S _ { T + } ^ { T C } - \frac { \gamma } { 2 } ( x _ { 0 } - A ) ^ { 2 } ,$$

which is equivalent to choosing the stock price S T at terminal time as the reference price. This model is referred to as an target close model [27][3], of which the optimal strategy is given by

$$x _ { t } = A + ( x _ { 0 } - A ) \cdot T C _ { t } ,$$

$$T C _ { t } \coloneqq \frac { \sinh \kappa T - \sinh \kappa t } { \sinh \kappa T } .$$

We refer to the strategy TC t in (9) as the unit target close (TC) order . Thus, similar to the case of implementation shortfall order in Section 4.2, the trajectory in (8) can be interpreted as executing x 0 -A unit TC orders if a broker is missioned to make transition of his position from x 0 to A shares. Likewise as for the unit IS orders, we show in Section 4.4 that the unit TC orders are used as the other building blocks for the where

construction of optimal trajectories for more general reference strategies.

Figure (3b) shows examples of plots for unit target close orders in different values of κ . We observe that the trading trajectories are concave in time as opposed to convex in time as that of the unit IS orders. Also, as κ increases, the optimal trajectory moves towards the reference strategy and towards the TWAP trajectory as κ decreases. In fact, similar to the case for implementation shortfall, in the limit as κ → 0 , the unit TC order (9) converges to the TWAP strategy: for any t ∈ [0 , T ] ,

$$\lim _ { \kappa \to 0 } T C _ { t } = \lim _ { \kappa \to 0 } \frac { \sinh \kappa T - \sinh \kappa t } { \sinh \kappa T } = 1 - \frac { t } { T } ;$$

whereas in the other extreme as κ → + ∞ , the optimal trajectory converges to a block trade at terminal time T :

$$\lim _ { \kappa \to \infty } T C _ { t } & = \lim _ { \kappa \to \infty } \frac { \sinh \kappa T - \sinh \kappa t } { \sinh \kappa T } = 1 - \lim _ { \kappa \to \infty } e ^ { - \kappa ( t - T ) } \cdot \frac { 1 - e ^ { - \kappa t } } { 1 - e ^ { - \kappa T } } = \begin{cases} 0 , \, 0 \leq t < T , \\ 1 , \, t = T . \end{cases}$$

## 4.3 Endpoints-only reference strategy

In this section, we consider the following reference strategy R t , which we called the endpoints-only .

$$R _ { t } = \begin{cases} x _ { 0 } , t = 0 , \\ R , 0 < t < T , \\ A , t = T . \end{cases}$$

The strategy is simply to hold R shares during the entire reallocation process, except at the initial and terminal times,.

The following lemma will prove itself useful in the determination of the optimal strategy subject to the reference strategy (10).

## Lemma 1. We have that

$$& \frac { \kappa } { \sinh \kappa T } \int _ { 0 } ^ { T } \left ( \sinh ( \kappa \min ( s , t ) ) \sinh ( \kappa ( T - \max ( s , t ) ) ) \right ) d s \\ = & \frac { \sinh \kappa T - \sinh \kappa t } { \sinh \kappa T } - \frac { \sinh \kappa ( T - t ) } { \sinh \kappa T } \\ = & T C _ { t } - I S _ { t } .$$

In other words, the given integral can be written as the difference between a unit TC and a unit IS order.

We summarize the result for optimal strategies subject to (10) in the proposition that follows.

Proposition 2. With the reference strategy given in (10), the optimal trajectory is given by an affine combination of a unit IS order and a unit TC order as

$$x _ { t } = \left ( x _ { 0 } - \frac { \mu } { \theta \sigma ^ { 2 } } - R \right ) \cdot I S _ { t } + \left ( - A + \frac { \mu } { \theta \sigma ^ { 2 } } + R \right ) \cdot T C _ { t } + A .$$

Note that when µ = 0 and R = x 0 , the optimal strategy reduces to the following TC strategy as in (8)

$$x _ { t } = ( x _ { 0 } - A ) \cdot T C _ { t } + A ;$$

whereas when µ = 0 and R = A , the optimal strategy reduces to the following IS strategy as in (6)

$$x _ { t } = ( x _ { 0 } - A ) \cdot I S _ { t } + A .$$

Note that for any given reference level R , the optimal trajectory in (11) at any point in time is an affine combination of a unit IS order and a unit TC order. The coefficients represent a trade-off between the two strategies. For example, if R is closer to the initial position x 0 and further away from the target position A , the strategy in (11) suggests we weigh in more on the unit TC order and less on the unit IS order; conversely, one should then weigh in more on the unit IS order. Figure (4) shows the plots of optimal trajectories in different reference levels R , assuming x 0 = 1 and A = 0 . Again, we end up with a unit TC order when R = x 0 and a unit IS order when R = A .

Figure 4: Optimal strategies in different reference levels R .

line chart

The image is a pair of graphs, each depicting a different strategy in a game. The left graph shows the optimal strategy, represented by a dashed line, while the right graph shows the reservation strategy, represented by a dotted line. The optimal strategy starts at a higher value and decreases over time, while the reservation strategy starts at a lower value and increases over time. The optimal strategy reaches a peak at around 0.5, while the reservation strategy reaches a peak at around 0.25. The optimal strategy is more volatile, with larger fluctuations, while the reservation strategy is more stable, with smaller fluctuations.

![Image](C:\Users\KITES\Desktop\Projekt2025\data\OpenRAGBench\out\2401.03305v2_artifacts\image_000003_185ec9d774fa5d922bc1f5d2c46e0de7943f7be59768355bc5fb0df5e1741cef.png)

As shown in Figure 4, when R &gt; x 0 = 1 the optimal strategy suggest overshoot the target, meaning buying more than needed then sell back later and quicker when time approaches the terminal time. On the other hand, if R &lt; A = 0 , the optimal strategy suggests undershoots the target. We provide conditions on the parameters under which an overshooting or an undershooting occur in the following proposition.

Proposition 3. Without loss of generality, assume x 0 &gt; A . Let x t be the optimal strategy given in (11) . We have that, if R + µ θσ 2 &gt; x 0 , then x t is concave in t and it becomes convex in t if R + µ θσ 2 &lt; A . It follows that x t overshoots if and only if

$$R + \frac { \mu } { \theta \sigma ^ { 2 } } > x _ { 0 } + \frac { 1 } { \cosh \kappa T - 1 } \cdot ( x _ { 0 } - A )$$

and it undershoots if and only if

$$R + \frac { \mu } { \theta \sigma ^ { 2 } } < A - \frac { 1 } { \cosh \kappa T - 1 } \cdot ( x _ { 0 } - A ) .$$

It appears that, when µ is nonzero, the terms in the optimal trajectory (11) that have µ involved always come in the form of µ θσ 2 . We provide a financial rationale of this combination of parameters as follows. Note that the combination resembles the Merton ratio in Merton's optimal portfolio problem in the market consisting of two assets: one risky and the other risk-less. The agent is risk averse with power utility u ( x ) = x γ and the dynamic of risky asset is governed by a geometric Brownian motion with expected return µ and volatility σ . The risk-less asset is assumed accruing zero interest. In this setting, the Merton ratio, which represents the percentage of wealth invested in the risky asset, is given by µ (1 -γ ) σ 2 . In our setting, the broker is with exponential utility u ( x ) = 1 θ (1 -e -θx ) and the stock price S t is assumed following an arithmetic Brownian motion with drift µ and volatility σ , i.e.,

$$d S _ { t } = \mu d t + \sigma d W _ { t } .$$

As in the derivation of the Merton ratio in Merton's problem, one may show that the 'Merton ratio' [28] in this case is given by µ θσ 2 except that this ratio does not represent the percentage of wealth invested in the risky asset as in the original Merton's problem. Indeed, this ratio represents the number of shares to be held in the optimal portfolio.

## 4.4 Piece-wise constant reference strategy

We consider in this section the reference strategies that are piece-wise constant across time. The consideration is that, to possibly account for real time market environments during the entire reallocation process, the broker's strategies may be subject to interval TWAP or VWAP strategies. For example, in an intraday trading activity, it is documented that the market trades much more actively at the times close to opening and closing than that in the middle of common trading days. Also, in the case where trading horizon across multiple days, the broker is most likely treating each trading day individually. In these regards, a piece-wise constant reference strategy is considered plausible.

Theoretically, as will be demonstrated, optimal trajectories subject to piece-wise constant reference strategies exhibit an elegant algebraic structure, derived from the unit IS and unit TC orders discussed in Sections 4.2. By applying standard approximation and limiting processes for integrable functions, this structure offers practical and insightful guidance for developing optimal strategies under general integrable reference strategies. Concretely, a generic piece-wise constant reference strategy R t is defined as

$$R _ { t } = ( x _ { 0 } - R ^ { ( 1 ) } ) \, \mathbb { I } _ { t = 0 } \, + \sum _ { k = 1 } ^ { n } R ^ { ( k ) } \, \mathbb { I } _ { \{ \frac { ( k - 1 ) T } { n } \leq t \leq \frac { k T } { n } \} } + A \, \mathbb { I } _ { \{ t = T \} } ,$$

where 1 {·} denotes the indicator function, n is the number of periods, and the R ( k ) 's are fixed constants. The following proposition summarizes the optimal trajectory under the piece-wise constant reference strategy in (12).

Proposition 4. When µ = m 0 = 0 , β → + ∞ , denote R (0) := x 0 and R ( n +1) := A , the solution to the previous optimization problem under the piece-wise constant reference strategy given in (12) is of the following form, for 1 ≤ k ≤ n ,

$$x _ { t } = & \left \{ a _ { k } + \left ( R ^ { ( k ) } - a _ { k } \right ) T C _ { t - \frac { ( k - 1 ) T } { n } } + \left ( a _ { k - 1 } - R ^ { ( k ) } \right ) I _ { t - \frac { ( k - 1 ) T } { n } } \right \} 1 _ { \{ \frac { ( k - 1 ) T } { n } \leq t < \frac { T } { n } \} } , \\ \intertext { w i t h \, \kappa \, = \, \sqrt { \frac { 9 \frac { 2 ^ { n } } { 2 n } } { 2 n } } , } & \quad \mathbb { I } _ { S } \colon = \frac { \sinh \kappa \left ( \frac { T } { n } - t \right ) } { \sinh \kappa \frac { T } { n } } , \quad T C _ { t } \colon = \frac { \sinh \kappa \frac { T } { n } - \sinh \kappa t } { \sinh \kappa \frac { T } { n } } ,$$

$$IS _ { t } \coloneqq \frac { \sinh \kappa \left ( \frac { T } { n } - t \right ) } { \sinh \kappa \frac { T } { n } } , \quad T C _ { t } \coloneqq \frac { \sinh \kappa \frac { T } { n } - \sinh \kappa t } { \sinh \kappa \frac { T } { n } } ,$$

and a k is denoted as a weighted average of R ( i ) 's:

$$a _ { k } \coloneqq \frac { \sinh \kappa \left ( T - \frac { k T } { n } \right ) } { \sinh \kappa T } \cdot \sum _ { i = 0 } ^ { k } b _ { i } R ^ { ( i ) } + \frac { \sinh \kappa \frac { k T } { n } } { \sinh \kappa T } \cdot \sum _ { i = k + 1 } ^ { n + 1 } b _ { n - i + 1 } R ^ { ( i ) } , \ 1 \leq k \leq n - 1 ,$$

where

$$b _ { i } = \begin{cases} 1 , & i = 0 , \\ \cosh \left ( \kappa \frac { i T } { n } \right ) - \cosh \left ( \kappa \frac { ( i - 1 ) T } { n } \right ) , & 1 \leq i \leq n - 1 . \end{cases}$$

Notice that the IS t and TC t in Proposition 4 are indeed respectively the unit IS order given in (7) and the unit TC order in (9). Proposition 4 essentially states that, for a given piece-wise constant reference strategy, its corresponding optimal solution in each sub-interval is given by an affine transformation of a unit IS order and a unit TC order. In this sense we may regard the unit IS orders and the unit TC orders obtained in Sections 4.2 as the building blocks or bases for optimal trajectories under piece-wise constant reference strategies. The algebraic structure of the optimal trajectories is thus depicted by the affine space generated by the unit IS and unit TC orders. What are left to be determined are the coefficients that are sub-interval dependent. In practice, one should firstly calculate a k 's by linear combinations of R ( i ) 's, then optimal strategy is obtained by connecting a k 's using unit IS and unit TC orders. As an example, Figure (5) shows the plots of a piece-wise constant reference strategy (in dotted red) its optimal trajectory (in blue) with three sub-intervals n = 3 , the other parameters are given by T = 3 , κ = 5 , R (1) = 15 2 , R (2) = 9 2 , R (3) = 3 2 , x 0 = 9 , A = 0 . To conclude the

Figure 5: A three-period piece-wise constant reference strategy and its corresponding optimal trajectory.

line chart

The image is a line graph with two lines, one solid and one dashed, plotted against a time axis from 0 to 30. The solid line starts at 9, decreases to 0, and then increases to 1. The dashed line starts at 7.5, decreases to 4.5, and then increases to 7.5.

![Image](C:\Users\KITES\Desktop\Projekt2025\data\OpenRAGBench\out\2401.03305v2_artifacts\image_000004_d89ddef110f1480b5768203c4024ce99bcda21795cea21a4dd5226436eb40fcd.png)

section, we show in Theorem 3 a stability theorem for optimal strategies subject to general, smooth enough, reference strategies.

Theorem 3. For any given reference strategies R t and ˜ R t satisfying

$$\int _ { 0 } ^ { T } \left ( R _ { t } - \widetilde { R } _ { t } \right ) ^ { 2 } d t < \varepsilon ,$$

for some ε &gt; 0 . Let x t and ˜ x t be the corresponding optimal trajectories for R t and ˜ R t , respectively. We have that, for any 0 ≤ t ≤ T ,

$$| x _ { t } - \widetilde { x } _ { t } | < \frac { 1 } { 2 } \sqrt { \kappa \varepsilon } .$$

The above theorem basically states the fact that when two reference strategies are close in the L 2 sense, their corresponding optimal strategies remain close in the sup norm sense. Note that for any ε &gt; 0 and an almost everywhere continuous bounded RS R t , there exists a piece-wise constant RS ˜ R t such that

$$\int _ { 0 } ^ { T } \left ( R _ { t } - \widetilde { R } _ { t } \right ) ^ { 2 } d t < \varepsilon ,$$

It follows that the optimal trajectory in (13) for ˜ R t , which is an affine transformation of unit IS and unit TC orders in each sub-interval, can be applied as an approximation to the optimal trajectory under reference strategy R t , with error estimate given in Theorem 3.

## 5 Numerical examples

We conduct in this section numerical experiments on the implementation of optimal strategy obtained in Theorem 1 and stress testing the strategy against various parameters. Monte Carlo simulations are implemented to illustrate sample trading trajectories and the performances criteria of the optimal strategy versus those of a related TWAP strategy. The performance of the optimal and TWAP strategies are then stress tested against certain extreme parameters. We remark that the parameters chosen for the numerical examples in this section are for convenience only. In practice, parameters are supposedly calibrated to market data prior to implementation, causing possible issues associated with estimation risk.

## 5.1 Sample trading trajectories

We present in Figures (6) through (11) sample trading trajectories under the optimal and a related TWAP strategies in various parameters. Parameters chosen as base case are ( m 0 , η, ρ, θ, σ, β ) = (0 . 05 , 10 , 0 , 0 . 002 , 200 , 1000) . Table 1 summarizes the parameters that vary, while the others are held fixed, in each case and their corresponding figures. The reference strategy R t is selected as a block trade at t = 0 , as shown in Section 4.2.

Figure (6) illustrates sample trading trajectories for the optimal and the TWAP strategies in different values of m 0 . We note that, since m 0 quantifies the execution risk, as m 0 increases both trajectories become more volatile and fluctuating.

Table 1: Sample trading trajectory in varying parameters

| Figure number   | Parameter   |   Case 1 |   Case 2 |    Case 3 |
|-----------------|-------------|----------|----------|-----------|
| Figure 6        | m 0         |    0     |    0.05  |     0.1   |
| Figure 7        | η           |    5     |   10     |    20     |
| Figure 8        | ρ           |   -0.9   |    0     |     0.9   |
| Figure 9        | θ           |    0.001 |    0.002 |     0.004 |
| Figure 10       | σ           |  100     |  200     |   400     |
| Figure 11       | β           |  100     | 1000     | 10000     |

Figure 6: Sample trading trajectories in different m 0

line chart

The image is a line graph that compares the performance of two different algorithms, "Optimal" and "TWAP", over three different values of a parameter "m0". The x-axis represents "m0" and the y-axis represents the performance of the algorithms. The "Optimal" algorithm consistently outperforms the "TWAP" algorithm across all three values of "m0". The "TWAP" algorithm shows a significant decrease in performance as "m0" increases, while the "Optimal" algorithm shows a more gradual decrease.

![Image](C:\Users\KITES\Desktop\Projekt2025\data\OpenRAGBench\out\2401.03305v2_artifacts\image_000005_f2bb3fbffbd97b24220e90a4f0ce0248dafab2b26107e68c43a588de6a4b797c.png)

Figure (7) exhibits sample trading trajectories in varying values of η . It is worth mentioning that, since η reflects the level of transaction costs, as the value of η increases, transaction cost becomes more significant in the determination of optimal strategies. Consequently, the optimal strategy tends to align more closely with the classical TWAP strategy. In other words, a higher η places greater emphasis on minimizing transaction costs, motivating the adoption of a strategy that mirrors the TWAP approach, which aims for consistent execution over time.

Figure (8) shows optimal strategies in the values of ρ = -0 . 5 , 0 , 0 . 5 . Recall that ρ denotes the correlation between the stock price and the execution risk. We note that there seems no significant dependence of the optimal strategies on ρ within this set of parameters.

Figure 7: Sample trading trajectories in different η

line chart

The image is a line graph with three different lines, each representing a different variable. The x-axis is labeled with numbers ranging from 0 to 100. The y-axis is labeled with numbers ranging from 0 to 1.0. The lines are labeled as "optimal", "TWAP", and "TWAP-optimal". The "optimal" line is the highest and the "TWAP" and "TWAP-optimal" lines are the lowest. The "TWAP" line is the most stable and the "TWAP-optimal" line is the most variable.

![Image](C:\Users\KITES\Desktop\Projekt2025\data\OpenRAGBench\out\2401.03305v2_artifacts\image_000006_5e0e1c6189245346e2601afb17e1e5b0e5251b4101a8ab4de43575a3b6378bfd.png)

Figure 8: Sample trading trajectories in different ρ

line chart

The image shows three graphs with different trends.

![Image](C:\Users\KITES\Desktop\Projekt2025\data\OpenRAGBench\out\2401.03305v2_artifacts\image_000007_3caddd071accdceffb7079ad026d836ccd19917c07cce1469997b47c50e16a8d.png)

Figure (9) illustrates the optimal strategies in the values of θ = 0 . 001 , 0 . 002 , 0 . 004 , which represents the broker's taste of risk aversion. The larger the value of θ , the more risk averse the broker tends to be. It follows that the sample trading trajectory under optimal strategy gradually converges towards the reference strategy as θ increases, indicating the broker's inclination to adopt a more conservative and risk-averse approach.

Figure 9: Sample trading trajectories in different θ

line chart

The image is a line graph with three different lines, each representing a different variable. The x-axis is labeled with values ranging from 0 to 100, and the y-axis is labeled with values ranging from 0 to 1.0. The lines are labeled as "optimal", "TWAP", and "TWAP-optimal". The "TWAP" line is the highest and the "TWAP-optimal" line is the lowest.

![Image](C:\Users\KITES\Desktop\Projekt2025\data\OpenRAGBench\out\2401.03305v2_artifacts\image_000008_1aa5cf6acf7099e006dfbeb30e0195a944b77cd61506eac25974cbb66b7915cf.png)

Figure (10) shows sample trading trajectories under optimal strategies with respect to the stock volatility σ = 100 , 200 , 400 . As σ increases, the price risk increases. Thus, to mitigate the risk incurred from the price volatility during execution, the optimal strategy tracks more closely to the reference strategy.

Figure 10: Sample trading trajectories in different σ

line chart

The image is a line graph that compares the performance of two different algorithms, Optimal and TWAP, over three different parameter values (σ=100, σ=200, and σ=400). The x-axis represents the parameter values, while the y-axis represents the performance of the algorithms.

![Image](C:\Users\KITES\Desktop\Projekt2025\data\OpenRAGBench\out\2401.03305v2_artifacts\image_000009_55bd8a0bb0447784abf51d79d7285cf55daf8e9e7de363981d75524be69e04b8.png)

Figure (11) presents the optimal strategies in the values of β = 100 , 1000 , 10000 , which quantifies the penalty of block trade at terminal time. Large β indicates that any remaining inventory at terminal time is unfavorable. Therefore, it is seen in the figure that the terminal inventory x ∗ T of the sample trading trajectories under optimal strategy gradually approaches zero. It is thus fathomable that, as β approaches infinity, a final block trade at terminal time turns into strictly prohibited.

Figure 11: Sample trading trajectories in different β

line chart

The image shows a comparison of two functions, "optimal" and "TWAP", over a range of x-values.

![Image](C:\Users\KITES\Desktop\Projekt2025\data\OpenRAGBench\out\2401.03305v2_artifacts\image_000010_626cf181b3415010ba39fe8053e261b19c5c443b53f3578f73f1ca265279a7f0.png)

## 5.2 Performance analysis and stress test

To demonstrate the performance of the optimal strategy against TWAP, we implement the strategies using Monte Carlo simulations and present the resulting histograms and boxplots of the terminal wealths as well as the utilities at the investment horizon. This performance analysis serves to illustrate the optimality and robustness of the optimal strategy.

Figure 12: Histograms and boxplots of terminal wealths and utilities under the optimal and the TWAP strategies. Terminal wealth on the left, utility on the right. Vertical dashed lines indicate sample means.

bar chart

The image consists of two graphs, each showing the distribution of a certain variable, with the x-axis representing the variable and the y-axis representing the frequency or density of the variable. The graphs are identical in terms of the x-axis, but differ in the shape of the y-axis. The first graph has a linear scale, while the second graph has a logarithmic scale. The first graph has a peak at the maximum value of the variable, while the second graph has a peak at the minimum value of the variable. The first graph has a bell-shaped curve, while the second graph has a flat line. The first graph has a sharp decline, while the second graph has a gentle decline. The first graph has a sharp decline, while the second graph has a gentle decline. The first graph has a sharp decline, while the second graph has a gentle decline. The first graph has

![Image](C:\Users\KITES\Desktop\Projekt2025\data\OpenRAGBench\out\2401.03305v2_artifacts\image_000011_c7ea17caff469101fb9793bbe94fe6d1425238672bcc21a9473e7a91df615d59.png)

Figure (12) exhibits the histograms and boxplots of the terminal P&amp;L (on the left) and the utility (on the left) at investment horizon for the optimal and the TWAP strategies. We observe that the optimal

Table 2: Stress testing parameters

|                         |   m 0 |    η |   ρ |     θ |    σ |     β |
|-------------------------|-------|------|-----|-------|------|-------|
| Baseline                |  0.05 | 10   |   0 | 0.002 |  200 | 1e+06 |
| Scenario 1 (large σ )   |  0.05 | 10   |   0 | 0.002 | 2000 | 1e+06 |
| Scenario 2 (large β )   |  0.05 | 10   |   0 | 0.002 |  200 | 1e+07 |
| Scenario 3 (large m 0 ) |  5    | 10   |   0 | 0.002 |  200 | 1e+06 |
| Scenario 4 (small η )   |  0.05 |  0.1 |   0 | 0.002 |  200 | 1e+06 |

strategy not only consistently achieves higher average terminal wealth and utility than those under TWAP but also bears lower variability. Furthermore, an intriguing observation is made regarding the tail ends of the distribution. Specifically, the TWAP strategy demonstrates a greater density in these tail regions, indicating a higher likelihood of incurring significant losses when compared to our optimal strategy. This discrepancy in density at the tail end reinforces the notion that the TWAP strategy may accentuate the potential for unfavorable outcomes, thus reflecting a subpar approach to risk management.

Finally, we stress test the optimal and the TWAP strategies against extreme parameters. While the remaining parameters are held the same as in the benchmark case, the stock volatility σ is scaled up by ten folds in Scenario 1, the terminal penalty coefficient β up by ten folds in Scenario 2, the execution risk m 0 up by a hundred folds in Scenario 3, and lastly in Scenario 4 down by 0.1 hundred folds the temporary cost η . Table 2 summarizes the parameters that are stress tested in each scenario and Figure 13 shows the histograms and boxplots of P&amp;Ls at the terminal time under the optimal and the TWAP strategies.

Apparently, in all the scenarios the histograms under optimal strategies are concentrated around zero whereas those under TWAP strategies are much more widely spreading. Also, the sample means under optimal strategies are higher than those of TWAP strategies. We conclude that, even under extreme situations, the optimal strategies outperform TWAP strategies not only in higher averaged P&amp;L but also with lower volatility risk, which shows the robustness of our results.

Figure 13: Histograms and boxplots of terminal P&amp;L under stress tests. Scenarios 1 on the top left, 2 on the top right, 3 on the bottom left, and 4 on the bottom right. Vertical dashed lines indicate sample means.

bar chart

The image is a collection of four graphs, each depicting a different type of data. The first graph shows a line graph with a title "TWAP optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal optimal

![Image](C:\Users\KITES\Desktop\Projekt2025\data\OpenRAGBench\out\2401.03305v2_artifacts\image_000012_64e42194784f001cc9adab5d7d23ddd52a8db39085e99c1ac93a328e68454be8.png)

## 6 Conclusion

In this article, we showed how the broker's order execution problem under execution risk subject to client's reference strategy can be recast as a utility maximization problem. The optimal solution to the utility maximization problem was obtained by solving an associated Riccati differential equation and was presented in feedback form. When execution risk vanishes, the optimal strategies become deterministic and were given in closed form. We showed that trading trajectories subject to the unit IS and the unit TC orders form a basis of an affine structure for trading trajectories under optimal strategies subject to general piece-wise constant reference strategies. As for general continuous reference strategies, we proved an approximation and stability theorem for the trading trajectory under the corresponding optimal strategy via the trajectories from piece-wise constant reference strategies.

Numerical experiments showed that the optimal strategies not only achieve higher expected values but also bear lower variabilities as opposed to those under TWAP strategies. Numerical performance analysis and stress tests confirmed that optimal strategies outperform TWAP strategies, by a wide margin in certain cases. Possible extensions of the framework considered in the paper include (a) a stochastic component to the price evolution reflecting the overall market activity such macroeconomics factors or news; (b) the price impact, rather than permanent, being transient with proper decay kernel. We leave these considerations to a future study.

## Acknowledgement

This research is supported by the National Natural Science Foundation of China (Grants No.11971040).

## A Appendix

## A.1 Proof to Proposition 1

By Itô's formula,

$$( x _ { T } - A ) S _ { T } & = ( x _ { 0 } - A ) S _ { 0 } + \int _ { 0 } ^ { T } S _ { t } d x _ { t } + \iint _ { 0 } ^ { T } \left ( \mu ( x _ { t } - A ) + \rho \sigma m ( v _ { t } ) - \gamma v _ { t } ( x _ { t } - A ) \right ) d t \\ & + \int _ { 0 } ^ { T } \sigma ( x _ { t } - A ) d W _ { t } + \int _ { 0 } ^ { T } \gamma ( x _ { t } - A ) m ( v _ { t } ) d Z _ { t } .$$

Furthermore, note that ˜ S t = S t + ηv t ,

$$\int _ { 0 } ^ { T } \left ( - \tilde { S } _ { t } \right ) \text {d} x _ { t } = - \int _ { 0 } ^ { T } S _ { t } \text {d} x _ { t } - \int _ { 0 } ^ { T } \eta v _ { t } ^ { 2 } \text {d} t + \int _ { 0 } ^ { T } \eta v _ { t } m ( v _ { t } ) \text {d} Z _ { t } ,$$

in summary,

$$\Pi = & ( x _ { T } - A ) S _ { T } - \beta ( x _ { T } - A ) ^ { 2 } + \int _ { 0 } ^ { T } \left ( - \tilde { S } _ { T } \right ) d x _ { t } \\ = & ( x _ { 0 } - A ) S _ { 0 } - \beta ( x _ { T } - A ) ^ { 2 } + \int _ { 0 } ^ { T } \left ( \mu ( x _ { t } - A ) + \rho \sigma m ( v _ { t } ) - \eta v _ { t } ^ { 2 } - \gamma v _ { t } ( x _ { t } - A ) \right ) d t \\ & + \int _ { 0 } ^ { T } \sigma ( x _ { t } - A ) d W _ { t } + \int _ { 0 } ^ { T } ( \eta v _ { t } + \gamma ( x _ { t } - A ) ) m ( v _ { t } ) d Z _ { t } .$$

## A.2 Risk-Neutral Case of Theorem 1

In Section (3) we recast the optimal execution problem as a utility maximization problem with the CARA preference u ( x ) = 1 θ (1 -e -θx ) with parameter θ &gt; 0 , which reflects the broker's risk aversion. As θ → 0 , the utility function u ( x ) = lim θ → 0 1 θ (1 -e -θx ) = x describes a risk-neutral preference. With the admissible set A and the excess P&amp;L ˜ Π given in Section (2.2) and Section (3), the risk-neutral expected utility is given by

$$\mathbb { E } \left [ u \left ( \tilde { \Pi } \right ) \right ] = \mathbb { E } \left [ \left [ - \beta ( x _ { T } - A ) ^ { 2 } + \int _ { 0 } ^ { T } \left ( \mu ( x _ { t } - R _ { t } ) + \rho \sigma ( m _ { t } ) - \nu p _ { t } ^ { 2 } - \gamma v _ { t } ( x _ { t } - A ) \right ) d t \\ + \int _ { 0 } ^ { T } \sigma ( x _ { t } - R _ { t } ) d W _ { t } + \int _ { 0 } ^ { T } \left ( \mu v _ { t } + \gamma ( x _ { t } - A ) m ( v _ { t } ) d Z _ { t } \right ] \\ = \mathbb { E } \left [ - \beta ( x _ { T } - A ) ^ { 2 } + \int _ { 0 } ^ { T } \left ( \mu ( x _ { t } - R _ { t } ) + \rho \sigma ( m _ { t } ) - \nu p _ { t } ^ { 2 } - \gamma v _ { t } ( x _ { t } - A ) \right ) d t \right ] .$$

When the execution risk is constant (i.e. m ( · ) ≡ m 0 for some m 0 ≥ 0 ), the utility maximization problem reduces to the following Stochastic Linear Quadratic (SLQ) control problem [22]:

$$\begin{cases} \sup _ { v \in A } \mathbb { E } \left [ - \beta ( x _ { T } - A ) ^ { 2 } + \int _ { 0 } ^ { T } \left ( \mu ( x _ { t } - R _ { t } ) + \rho \sigma m _ { 0 } - \eta v _ { t } ^ { 2 } - \gamma v _ { t } ( x _ { t } - A ) \right ) d t \right ] , \\ s . t . \ x _ { t } = x _ { 0 } - \int _ { 0 } ^ { t } v _ { s } d s + m _ { 0 } Z _ { t } . \end{cases}$$

Define the value function V ( t, x ) as

$$V ( t , x ) = \sup _ { v \in \mathcal { A } _ { t } } \mathbb { E } \left [ - \beta ( x _ { T } - A ) ^ { 2 } + \int _ { t } ^ { T } \left ( \mu ( x _ { s } - R _ { s } ) + \rho \sigma m _ { 0 } - \eta v _ { s } ^ { 2 } - \gamma v _ { s } ( x _ { s } - A ) \right ) d s \Big | x _ { t } = x \right ] ,$$

where A t := { v is progressively measurable in [ t, T ] and ∫ T t E [ v 2 s ]d s &lt; ∞ } . Note that our problem satisfies assumption (L1) given in Section 3.1 of [22] due to the boundedness of the coefficients, so the problem is solvable, and by the dynamic programming principle, the value function V is unique satisfying the HamiltonJacobi-Bellman (HJB hereafter) equation

$$V _ { t } + \frac { 1 } { 2 } m _ { 0 } ^ { 2 } V _ { x x } + \sup _ { v \in \mathbb { R } } \left \{ - \eta v ^ { 2 } - v \left ( \gamma ( x - A ) + V _ { x } \right ) \right \} + \mu ( x - R _ { t } ) + \rho \sigma m _ { 0 } = 0$$

□

with terminal condition v ( T, x ) = -β ( x -A ) 2 . With first order criterion, the optimal feedback control is given by v ∗ = -1 2 η ( γ ( x -A ) + V x ) , hence the HJB equation reduces to

$$V _ { t } + \frac { 1 } { 2 } m _ { 0 } ^ { 2 } V _ { x x } + \frac { 1 } { 4 \eta } \left ( \gamma ( x - A ) + V _ { x } \right ) ^ { 2 } + \mu ( x - R _ { t } ) + \rho \sigma m _ { 0 } = 0 , \ \ v ( T , x ) = - \beta ( x - A ) ^ { 2 } .$$

Assume the Ansarz for value function V

$$V ( t , x ) = a ( t ) x ^ { 2 } + b ( t ) x + c ( t ) .$$

Plug the Ansarz into the HJB equation yields the Riccati ODE system

$$\begin{cases} a ^ { \prime } ( t ) + \frac { 1 } { 4 \eta } ( 2 a ( t ) + \gamma ) ^ { 2 } = 0 , & a ( T ) = - \beta , \\ b ^ { \prime } ( t ) + \frac { 1 } { 2 \eta } ( 2 a ( t ) + \gamma ) ( b ( t ) - \gamma A ) + \mu = 0 , & b ( T ) = 2 \beta A , \\ c ^ { \prime } ( t ) + m _ { 0 } ^ { 2 } a ( t ) + \frac { 1 } { 4 \eta } ( b ( t ) - \gamma A ) ^ { 2 } - \mu R _ { t } + \rho \sigma m _ { 0 } = 0 , & c ( T ) = - \beta A ^ { 2 } . \end{cases}$$

By solving the ODE system, the deterministic functions a, b, c of time t are given by

$$a ( t ) & = - \ \frac { \eta } { T - t + \alpha } - \frac { \gamma } { 2 } , \\ b ( t ) & = \frac { \mu } { 2 } ( T - t + \alpha ) - \frac { \frac { 1 } { 2 } \mu \alpha ^ { 2 } - 2 A \eta } { T - t + \alpha } + \gamma A , \\ c ( t ) & = - \ m _ { 2 } \eta \log \frac { T - t + \alpha } { \alpha } + \left ( \rho ( \sigma _ { 0 } \eta - \frac { \gamma } { 2 } \eta _ { 0 } ^ { 2 } ) \left ( T - t \right ) } \\ & - \frac { \mu ^ { 2 \alpha } \alpha ^ { 3 } } { 1 6 \eta } \left ( \frac { \alpha } { T - t + \alpha } + \frac { 2 ( T - t + \alpha ) } { \alpha } - \frac { ( T - t + \alpha ) ^ { 3 } } { 3 \alpha ^ { 3 } } - \frac { 8 } { 3 } \right ) \\ & - \frac { A ^ { 2 \eta } - \frac { 1 } { 2 } \mu A \alpha ^ { 2 } } { T - t + \alpha } - \frac { \gamma A ^ { 2 } + \mu A ( T - t + \alpha ) } { 2 } + \int _ { t } ^ { T } \mu ( A - R _ { s } ) d s \\ \vdots & = \frac { 2 \eta } { 2 } \geq 0 , \, \text {Note that} \, V ( t , x ) \equiv a ( t ) x ^ { 2 } + b ( t ) x + c ( t ) \text { is continuous on } [ 0 , T ] \times \mathbb { R } \text { and } \text {cont}$$

where α := 2 η 2 β -γ &gt; 0 . Note that V ( t, x ) = a ( t ) x 2 + b ( t ) x + c ( t ) is continuous on [0 , T ] × R and continuously differentiable on (0 , T ) × R satisfying the HJB equation, therefore it must be the value function by the uniqueness of solutions to the HJB equation. Then the verification theorem gives rise to the optimal feedback control

$$v _ { t } ^ { * * } = & \frac { x _ { t } - A } { T - t + \alpha } - \frac { \mu } { 4 \eta } \left ( ( T - t + \alpha ) - \frac { \alpha ^ { 2 } } { T - t + \alpha } \right ) .$$

Due to the boundedness of 1 T -t + α and -A T -t + α -µ 4 η ( ( T -t + α ) -α 2 T -t + α ) , v ∗∗ ∈ A , which implies that the optimal control v ∗∗ lies in the admissible set. Moreover, the maximal risk-neutral expected utility is given by

$$\sup _ { v \in A } \mathbb { E } \left [ \tilde { \Pi } \right ] & = \mathbb { E } \left [ \tilde { \Pi } \right ] \Big | _ { v _ { 0 } = v ^ { * } } = V ( 0 , x _ { 0 } ) = a ( 0 ) x _ { 0 } ^ { 2 } + b ( 0 ) x _ { 0 } + c ( 0 ) \\ & = \left ( - \frac { \eta } { T + \alpha } - \frac { \gamma } { 2 } \right ) x _ { 0 } ^ { 2 } + \left ( \frac { \mu } { 2 } ( T + \alpha ) - \frac { \mu \rho ^ { 2 } } { 2 } \frac { - 2 A \eta } { T + \alpha } + \gamma A \right ) x _ { 0 } \\ & \quad - m _ { 0 } ^ { 2 } \eta \log \frac { T + \alpha } { \alpha } + \left ( \rho \sigma m _ { 0 } - \frac { \gamma } { 2 } m _ { 0 } ^ { 2 } \right ) T - \frac { \mu ^ { 2 } \alpha ^ { 3 } } { 1 6 \eta } \left ( \frac { \alpha } { T + \alpha } + \frac { 2 ( T + \alpha ) } { \alpha } - \frac { ( T + \alpha ) ^ { 3 } } { 3 \alpha ^ { 3 } } - \frac { 8 } { 3 } \right ) \\ & \quad - \frac { A \eta - \frac { 1 } { 2 } \mu A \alpha ^ { 2 } } { T + \alpha } - \frac { \gamma A ^ { 2 } + \mu A ( T + \alpha ) } { 2 } + \int _ { 0 } ^ { T } \mu ( A - R _ { s } ) d s < \infty .$$

## A.3 Proof to Theorem 1

Note that x t = x 0 -∫ t 0 v s d s + m 0 d Z t , by Itô's formula,

$$( x _ { T } - A ) ^ { 2 } = ( x _ { t } - A ) ^ { 2 } + \int _ { t } ^ { T } \left ( - 2 ( x _ { s } - A ) v _ { s } + m _ { 0 } ^ { 2 } \right ) \, d s + \int _ { t } ^ { T } \left ( 2 m _ { 0 } ( x _ { s } - A ) \right ) d Z _ { s } .$$

Furthermore, note that standard Brownian motions W t and Z t have constant correlation ρ , denote standard Brownian motion W 1 t = Z t -ρW t √ 1 -ρ 2 , then W 1 t and W t are independent. By extracting the constants and deterministic parts out of the expectation, the value function is given by

$$V ( t , x ) = \frac { 1 } { \theta } - \frac { 1 } { \theta } \cdot \exp \left ( - \int _ { t } ^ { T } \theta \left ( \mu ( A - R _ { s } ) + \rho \sigma m _ { 0 } - \beta m _ { 0 } ^ { 2 } \right ) d s + \theta \beta ( x - A ) ^ { 2 } \right ) \cdot V _ { 0 } ( t , x ) ,$$

where we observe the equivalent optimization problem

$$\text {where we observe this problem on optimization problem} \\ V _ { 0 } ( t , x ) & = \inf _ { v \in \mathcal { A } } \, \mathbb { E } \left [ \exp \left \{ \int _ { t } ^ { T } \left [ - \theta \mu ( x _ { s } - A ) + \theta \eta v _ { s } ^ { 2 } - \theta ( 2 \beta - \gamma ) v _ { s } ( x _ { s } - A ) \right ] d s \\ & + \int _ { t } ^ { T } \left [ ( - \theta \sigma - \theta ( \gamma - 2 \beta ) m _ { 0 } \rho ) \left ( x _ { s } - A \right ) - \theta \eta m _ { 0 } \rho v _ { s } + \theta \sigma ( R _ { s } - A ) \right ] d W _ { s } \\ & + \int _ { t } ^ { T } \left [ - \theta ( \gamma - 2 \beta ) m _ { 0 } \sqrt { 1 - \rho ^ { 2 } } ( x _ { s } - A ) - \theta \eta m _ { 0 } \sqrt { 1 - \rho ^ { 2 } } v \right ] d W _ { s } \right \} \Big | x _ { t } = x \right ] . \\ = & \colon \inf _ { v \in \mathcal { A } } \, \mathbb { E } \left [ \exp \left \{ J ( t , T ) \right \} | x _ { t } = x \right ] \\ \intertext { u r s t o c h a t i c r o n t l o b r a g h a s } \text { our stochastic control problem has a similar form as stochastic linear exponential} \text { quadratic (SI) EQ} \text { control}$$

Our stochastic control problem has a similar form as stochastic linear exponential quadratic (SLEQ) control problems given in [23] and [24], however, due to the constants and stochastic integrals appearing in our exponential function, these existing results can't be used directly. Instead, we follow the 'completing the square' technique used in [23], which is used to transform the integrand into a square form by introducing a Radon-Nikodym derivative. In this paper, we eliminate the stochastic integrals and 'complete the square' simultaneously by Girsanov's theorem. More precisely, we manage to find some probability measure Q ≪ P such that

$$\mathbb { E } ^ { \mathbb { P } } \left [ \exp \left \{ J ( t , T ) \right \} | x _ { t } = x \right ] = \mathbb { E } ^ { \mathbb { Q } } \left [ \frac { 1 } { L ( t , T ) } \cdot \exp \left \{ J ( t , T ) \right \} \right | x _ { t } = x \right ] ,$$

where 1 L ( t,T ) · exp { J ( t, T ) } can be transformed into a square form without Itô integrals. Concretely, suppose the Radon-Nikodym derivative is given by

$$\frac { d \mathbf Q } { d \mathbf P } \Big | _ { \mathcal { F } _ { t } } & = L ( t , T ) \coloneqq \exp \left \{ - \int _ { t } ^ { T } \Psi _ { 1 } ( s , x _ { s } , v _ { s } ) d W _ { s } - \int _ { t } ^ { T } \Psi _ { 2 } ( s , x _ { s } , v _ { s } ) d W _ { s } ^ { 1 } \\ & - \frac { 1 } { 2 } \int _ { t } ^ { T } \left ( \Psi _ { 1 } ^ { 2 } ( s , x _ { s } , v _ { s } ) + \Psi _ { 2 } ^ { 2 } ( s , x _ { s } , v _ { s } ) \right ) d s \right \} ,$$

where Ψ 1 and Ψ 2 are L 2 -functions to be determined. At the same time, for some deterministic function G 1 ( t ) and G 2 ( t ) such that G 1 ( T ) = G 2 ( T ) = 0 , by Ito's lemma,

$$- G _ { 1 } ( t ) ( x _ { t } - A ) ^ { 2 } - 2 G _ { 2 } ( t ) ( x _ { t } - A ) \\ = & ( G _ { 1 } ( T ) ( x _ { T } - A ) ^ { 2 } + 2 G _ { 2 } ( T ) ( x _ { T } - A ) ) - ( G _ { 1 } ( t ) ( x _ { t } - A ) ^ { 2 } + 2 G _ { 2 } ( t ) ( x _ { t } - A ) ) \\ = & \int _ { t } ^ { T } \left ( G _ { 1 } ^ { \prime } ( s ) ( x _ { s } - A ) ^ { 2 } + 2 G _ { 2 } ^ { \prime } ( s ) ( x _ { s } - A ) - 2 ( G _ { 1 } ( s ) ( x _ { s } - A ) + G _ { 2 } ( s ) ) v _ { s } + m _ { 0 } ^ { 2 } G _ { 1 } ( s ) ) \, d s \\ & + \int _ { t } ^ { T } 2 \rho m _ { 0 } ( G _ { 1 } ( s ) ( x _ { s } - A ) + G _ { 2 } ( s ) ) d W _ { s } + \int _ { t } ^ { T } 2 \sqrt { 1 - \rho ^ { 2 } } m _ { 0 } ( G _ { 1 } ( s ) ( x _ { s } - A ) + G _ { 2 } ( s ) ) d W _ { s } ^ { 1 } .$$

Hence,

$$H e n c , \\ \frac { 1 } { L ( t , T ) } \cdot \exp \{ J ( t , T ) \} \\ = \exp \{ J ( t , T ) - \log L ( t , T ) + ( - G _ { 1 } ( t ) ( x _ { t } - A ) ^ { 2 } - 2 G _ { 2 } ( t ) ( x _ { t } - A ) ) + ( G _ { 1 } ( t ) ( x _ { t } - A ) ^ { 2 } + 2 G _ { 2 } ( t ) ( x _ { t } - A ) ) \} \\ = \exp \{ \int _ { J } \left [ \int _ { \partial t } ^ { t } \left [ - \theta \mu ( x _ { t } - A ) + \theta \nu _ { s } ^ { 2 } - \theta ( 2 ^ { 3 } - \gamma ) \nu _ { s } ( x _ { s } - A ) + \frac { 1 } { 2 } \Psi _ { 1 } ^ { 2 } ( x _ { s } , x _ { s } ) + \frac { 1 } { 2 } \Psi _ { 2 } ^ { 2 } ( x _ { s } , x _ { s } , \theta _ { s } ) \right ] \\ + ( G _ { 1 } ^ { 1 } ( x _ { s } - A ) ^ { 2 } + 2 G _ { 2 } ^ { \prime } ( s ) ( x _ { s } - A ) - 2 ( G _ { 1 } ( s ) ( x _ { s } - A ) + G _ { 2 } ( s ) ) v _ { s } + m _ { 0 } ^ { 2 } G _ { 1 } ^ { \prime } ( ) ] d s \\ + \int _ { t } ^ { T } \left [ ( - \theta \sigma - \theta ( \gamma - 2 ) \beta ) m _ { 0 } \rho ( x _ { s } - A ) - \theta m _ { 0 } \rho v _ { s } + \theta \sigma ( R _ { s } - A ) + \Psi _ { 1 } ( s , x _ { s } , v _ { s } ) \\ + 2 \rho m _ { 0 } ( G _ { 1 } ( s ) ( x _ { s } - A ) + G _ { 2 } ( s ) ) \right ] d W _ { s } \\ + \int _ { t } ^ { T } \left [ ( - \theta ( \gamma - 2 ) \beta ) m _ { 0 } \sqrt { 1 - \rho ^ { 2 } } \beta \sqrt { ( x _ { s } - A ) } - \theta \eta m _ { 0 } \sqrt { 1 - \rho ^ { 2 } } v _ { s } + \Psi _ { 2 } ( s , x _ { s } , v _ { s } ) \\ + 2 \sqrt { 1 - \rho ^ { 2 } } m _ { 0 } ( G _ { 1 } ( s ) ( x _ { s } - A ) + G _ { 2 } ( s ) ) \right ] d W _ { s } \\ + ( G _ { 1 } ( t ) ( x _ { t } - A ) ^ { 2 } + 2 G _ { 2 } ( t ) ( x _ { t } - A ) ) \right ]$$

By setting

$$\begin{cases} \Psi _ { 1 } ( s , x _ { s } , v _ { s } ) = ( \theta \sigma + m _ { 0 } \rho ( \theta ( \gamma - 2 \beta ) - 2 G _ { 1 } ( s ) ) ) & ( x _ { s } - A ) + \quad \theta \eta _ { 0 } \rho v _ { s } - 2 m _ { 0 } G _ { 2 } ( s ) - \theta \sigma ( R _ { s } - A ) , \\ \Psi _ { 2 } ( s , x _ { s } , v _ { s } ) = ( \theta ( \gamma - 2 \beta ) - 2 G _ { 1 } ( s ) ) \, m _ { 0 } \sqrt { 1 - \rho ^ { 2 } } & ( x _ { s } - A ) + \quad \theta \eta _ { 0 } \sqrt { 1 - \rho ^ { 2 } } v _ { s } - 2 m _ { 0 } \sqrt { 1 - \rho ^ { 2 } } G _ { 2 } ( s ) , \end{cases}$$

the stochastic integrals ∫ T t · · · d W s and ∫ T t · · · d W 1 s appear to be zero. Moreover,

$$& \frac { 1 } { L ( t , T ) } \cdot \exp \{ \mathcal { J } ( t , T ) \} \\ = & \exp \left \{ \int _ { t } ^ { T } \left ( A ( s ) v _ { s } ^ { 2 } + B ( s ) ( x _ { s } - A ) v _ { s } + C ( s ) ( x _ { s } - A ) ^ { 2 } + D ( s ) v _ { s } + E ( s ) ( x _ { s } - A ) + F ( s ) \right ) d t , \right \} \\ & \quad + \left ( G _ { 1 } ( t ) ( x _ { t } - A ) ^ { 2 } + 2 G _ { 2 } ( t ) ( x _ { t } - A ) \right ) \left \{ \end{array}$$

where the coefficients are given by

$$\text {where the coefficient are given by} \\ H & \equiv A ( s ) \div \theta + \frac { 1 } { 2 } \theta ^ { 2 } \eta ^ { 2 } m _ { 0 } ^ { 2 } > 0 , \\ & \quad B ( s ) = - \theta ( 2 \beta - \gamma ) - 2 G _ { 1 } ( s ) + m _ { 0 } \theta ^ { 2 } \rho + \sigma \, \eta m _ { 0 } ^ { 2 } ( \theta ( \gamma - 2 \beta ) - 2 G _ { 1 } ( s ) ) , \\ & \quad C ( s ) = G _ { 1 } ^ { \prime } ( s ) + \frac { 1 } { m _ { 0 } ^ { 2 } } 2 \left ( \theta ( \gamma - 2 \beta ) - 2 G _ { 1 } ( s ) \right ) ^ { 2 } + \frac { 1 } { 2 } \theta ^ { 2 } \sigma ^ { 2 } + \theta \sigma p m _ { 0 } \left ( \theta ( \gamma - 2 \beta ) - 2 G _ { 1 } ( s ) \right ) , \\ & \quad D ( s ) = - 2 G _ { 2 } ( s ) - 2 m _ { 0 } \theta \rho G _ { 2 } ^ { \prime } ( s ) - m _ { 0 } \theta \rho ^ { 2 } \sigma ( R _ { s } - A ) , \\ & \quad E ( s ) = - \theta + \mu 2 ^ { \prime } G _ { 2 } ( s ) - 2 m _ { 0 } ^ { 2 } ( \theta ( \gamma - 2 \beta ) - 2 G _ { 1 } ( s ) ) G _ { 2 } ( s ) - \theta ^ { 2 } \sigma ^ { 2 } ( R _ { s } - A ) - 2 m _ { 0 } \theta \rho G _ { 2 } ( s ) \\ & \quad F ( s ) = m _ { 0 } \rho \theta \sigma ( \theta ( \gamma - 2 \beta ) - 2 G _ { 1 } ( s ) ) ( 1 3 - A ) \\ F ( s ) = m _ { 0 } ^ { 2 } G _ { 1 } ( s ) + 2 m _ { 0 } ^ { 2 } G _ { 2 } ^ { 2 } ( s ) + 2 \rho m _ { 0 } \theta \sigma ( R _ { s } - A ) G _ { 2 } ( s ) + \frac { 1 } { 2 } \theta ^ { 2 } \sigma ^ { 2 } ( R _ { s } - A ) ^ { 2 } . \\ \intertext { To make sure the integral in ( 14 ) behaves as a square form (plus constants), we rewrite it as a quadratic }$$

To make sure the integrand in (14) behaves as a square form (plus constants), we rewrite it as a quadratic function of v s :

$$A ( s ) v _ { s } ^ { 2 } + ( B ( s ) ( x _ { s } - A ) + D ( s ) ) \, v _ { s } + ( C ( s ) ( x _ { s } - A ) ^ { 2 } + E ( s ) ( x _ { s } - A ) + F _ { 0 } ( s ) ) + ( F ( s ) - F _ { 0 } ( s ) ) \, ,$$

of which the discriminant is set to be zero:

$$0 = \Delta = ( B ( s ) ( x _ { s } - A ) + D ( s ) ) ^ { 2 } - 4 A ( s ) \left ( C ( s ) ( x _ { s } - A ) ^ { 2 } + E ( s ) ( x _ { s } - A ) + F _ { 0 } ( s ) \right ) ,$$

hence,

$$\begin{cases} 0 = & B ^ { 2 } ( s ) - 4 A ( s ) C ( s ) , \\ 0 = & B ( s ) D ( s ) - 2 A ( s ) E ( s ) , \\ 0 = & D ^ { 2 } ( s ) - 4 A ( s ) F _ { 0 } ( s ) \implies F _ { 0 } ( s ) = \frac { D ^ { 2 } ( s ) } { 4 A ( s ) } . \end{cases}$$

Denote b 2 ( s ) := G 1 ( s ) + θ 2 (2 β -γ ) and b 1 ( s ) := 2 G 2 ( s ) , we may solve the ODEs b 2 ( · ) and b 1 ( · ) satisfy:

$$b _ { 2 } ^ { \prime } = \frac { 1 } { H } ( ( b _ { 2 } + l _ { 3 } ) ^ { 2 } - l _ { 1 } ) , \ \ b _ { 2 } ( T ) = \frac { \theta } { 2 } ( 2 \beta - \gamma ) ,$$

where l 3 = 1 2 m 0 ηθ 2 ρσ and l 1 = θ 2 σ 2 2 H . We may solve that

$$b _ { 2 } ( t ) = \sqrt { l _ { 1 } } \coth \left ( A _ { 0 } + \frac { \sqrt { l _ { 1 } } } { H } ( T - t ) \right ) - l _ { 3 } ,$$

$$A _ { 0 } \colon = \coth ^ { - 1 } \left ( \frac { l _ { 3 } + \frac { \theta } { 2 } ( 2 \beta - \gamma ) } { \sqrt { l _ { 1 } } } \right ) .$$

where

Moreover, we have b 1 solves the ODE

$$b _ { 1 } ^ { \prime } = \theta \mu + \frac { 1 } { H } b ( b _ { 2 } + l _ { 3 } ) + \frac { \eta \theta ^ { 2 } \sigma } { H } ( R _ { t } - A ) \left ( \theta \sigma + \frac { 1 } { 2 } m _ { 0 } ^ { 2 } \theta ^ { 2 } \eta \sigma ( 1 - \rho ^ { 2 } ) - \rho m _ { 0 } b _ { 2 } \right ) , \quad b _ { 1 } ( T ) = 0 .$$

With b 1 and b 2 solved, we may rewrite the integrand in (14) as

$$A ( s ) v _ { s } ^ { 2 } + B ( s ) ( x _ { s } - A ) v _ { s } + C ( s ) ( x _ { s } - A ) ^ { 2 } + D ( s ) v _ { s } + E ( s ) ( x _ { s } - A ) + F ( s ) \\ = & H \left ( v _ { s } - g _ { 1 } ( s ) ( x _ { s } - A ) - g _ { 0 } ( s ) \right ) ^ { 2 } + \left ( F ( s ) - \frac { D ^ { 2 } ( s ) } { 4 H } \right ) \\ = & H \left ( v _ { s } - g _ { 1 } ( s ) ( x _ { s } - A ) - g _ { 0 } ( s ) \right ) ^ { 2 } + \left ( m _ { 0 } ^ { 2 } \left ( b _ { 2 } - \frac { \theta } { 2 } ( 2 \beta - \gamma ) \right ) + \frac { \theta ^ { 2 } \sigma ^ { 2 } } { 2 } ( R _ { s } - A ) ^ { 2 } - \frac { 1 } { 4 H } \left ( b _ { 1 } - \rho m _ { 0 } \theta _ { \sigma } ^ { 2 } \sigma \eta ( R _ { s } - A ) \right ) ^ { 2 } \right ) ,$$

where

Denote we have

$$g _ { 1 } ( t ) \coloneqq \frac { ( 1 + m _ { 0 } ^ { 2 } \theta \eta ) b _ { 2 } - l _ { 3 } } { H } , \ g _ { 0 } ( t ) \coloneqq \frac { ( 1 + \theta \eta m _ { 0 } ^ { 2 } ) b _ { 1 } + 2 l _ { 3 } ( R _ { u } - A ) } { 2 H } .$$

$$c ( s ) \colon = m _ { 0 } ^ { 2 } \left ( b _ { 2 } - \frac { \theta } { 2 } ( 2 \beta - \gamma ) \right ) + \frac { \theta ^ { 2 } \sigma ^ { 2 } } { 2 } ( R _ { s } - A ) ^ { 2 } - \frac { 1 } { 4 H } \left ( b _ { 1 } - \rho m _ { 0 } \theta ^ { 2 } \sigma \eta ( R _ { s } - A ) \right ) ^ { 2 } , \ 0 \leq s \leq T ,$$

$$& \quad \text {we have} & \mathbb { E } ^ { \mathbb { P } } [ \exp \{ J ( t , T ) \} | x _ { t } = x ] = \mathbb { E } ^ { \mathbb { Q } } \left [ \frac { 1 } { L ( t , T ) } \cdot \exp \{ J ( t , T ) \} \Big | x _ { t } = x \right ] \\ & \quad = \mathbb { E } ^ { \mathbb { Q } } \Big [ \exp \left \{ \int _ { t } ^ { T } H ( v _ { s } - g _ { 1 } ( s ) ( x _ { s } - A ) - g _ { 0 } ( s ) ) ^ { 2 } d s \right \} \\ & \quad \cdot \exp \left \{ \left ( b _ { 2 } ( t ) - \frac { \theta } { 2 } ( 2 \beta - \gamma ) \right ) ( x _ { t } - A ) ^ { 2 } + b _ { 1 } ( t ) ( x _ { t } - A ) + \int _ { t } ^ { T } c ( s ) d s \right \} \Big | x _ { t } = x \right ] \\ & \quad = \mathbb { E } ^ { \mathbb { Q } } \Big [ \exp \left \{ \int _ { t } ^ { T } H ( v _ { s } - g _ { 1 } ( s ) ( x _ { s } - A ) - g _ { 0 } ( s ) ) ^ { 2 } d s \right \} \Big | x _ { t } = x \right ] \\ & \quad \cdot \exp \left \{ \left ( b _ { 2 } ( t ) - \frac { \theta } { 2 } ( 2 \beta - \gamma ) \right ) ( x - A ) ^ { 2 } + b _ { 1 } ( t ) ( x - A ) + \int _ { t } ^ { T } c ( s ) d s \right \} \\ & \quad \geq \exp \left \{ \left ( b _ { 2 } ( t ) - \frac { \theta } { 2 } ( 2 \beta - \gamma ) \right ) ( x - A ) ^ { 2 } + b _ { 1 } ( t ) ( x - A ) + \int _ { t } ^ { T } c ( s ) d s \right \} , \\ \intertext { where the equation holds when } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertextuser { \intertext { o n t i n g u s } } \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertextuser { \intertext { o n t i n g u s } } \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s } & \quad \intertext { o n t i n g u s$$

where the equation holds when v s = v ∗ s := g 1 ( s )( x s -A ) + g 0 ( s ) . Note that g 1 and g 0 are bounded and continuous on [0 , T ] , so v ∗ ∈ A t , hence,

$$V _ { 0 } ( t , x ) & = \inf _ { v \in \mathbb { A } } \mathbb { E } ^ { \mathbb { P } } \left [ \exp \left \{ J ( t , T ) \right \} | x _ { t } = x \right ] = \inf _ { v \in \mathbb { A } } \mathbb { Q } \left [ \frac { 1 } { L ( t , T ) } \cdot \exp \left \{ J ( t , T ) \right \} \right | x _ { t } = x \right ] \\ = & \mathbb { Q } \left [ \frac { 1 } { L ( t , T ) } \cdot \exp \left \{ J ( t , T ) \right \} \right | x _ { t } = x \right ] \Big | \Big | _ { v = v ^ { * } } \\ = & \exp \left \{ \left \{ \left ( b _ { 2 } ( t ) - \frac { \theta } { 2 } ( 2 \beta - \gamma ) \right ) ( x - A ) ^ { 2 } + b _ { 1 } ( t ) ( x - A ) + \int _ { t } ^ { T } c ( s ) d s \right \} .$$

Furthermore, the value function is given by

$$\text {For more} ; \text { the value function is given by} \\ V ( t , x ) = & \frac { 1 } { \theta } - \frac { 1 } { \theta } \cdot \exp \left \{ - \int _ { t } ^ { T } \theta \left ( \mu ( A - R _ { s } ) + \rho \sigma m _ { 0 } - \beta m _ { 0 } ^ { 2 } \right ) d s + \theta \beta ( x - A ) ^ { 2 } \right \} V _ { 0 } ( t , x ) \\ = & \frac { 1 } { \theta } - \frac { 1 } { \theta } \cdot \exp \left \{ \left ( b _ { 2 } ( t ) + \frac { \theta \gamma } { 2 } \right ) ( x - A ) ^ { 2 } + b _ { 1 } ( t ) ( x - A ) \\ & + \int _ { t } ^ { T } \left [ c ( s ) - \theta \mu ( A - R _ { s } ) - \theta \rho \sigma m _ { 0 } + \theta \beta m _ { 0 } ^ { 2 } \right ] d s \right \} . \\ = & \frac { 1 } { \theta } \left ( 1 - \exp \left \{ \left ( b _ { 2 } ( t ) + \frac { \theta \gamma } { 2 } \right ) ( x - A ) ^ { 2 } + b _ { 1 } ( t ) ( x - A ) + b _ { 0 } ( t ) \right \} \right ) , \\ \intertext { w h e r e } \text {where}$$

where

$$b _ { 0 } ( t ) & \colon = \int _ { t } ^ { T } \left [ c ( s ) - \theta \mu ( A - R _ { s } ) - \theta \rho \sigma m _ { 0 } + \theta \beta m _ { 0 } ^ { 2 } \right ] d s \\ & = \int _ { t } ^ { T } \left [ \frac { l _ { 1 } - l _ { 3 } ^ { 2 } } { H } ( R _ { s } - A ) ^ { 2 } + \left ( \theta \mu + \frac { l _ { 3 } } { H } b _ { 1 } \right ) ( R _ { s } - A ) + \left ( - \frac { b _ { 1 } ^ { 2 } } { 4 H } + m _ { 0 } ^ { 2 } \left ( b _ { 2 } + \frac { \theta \gamma } { 2 } \right ) - \rho m _ { 0 } \theta \sigma \right ) \right ] d s .$$

In summary, the optimal feedback control is given by

$$x = y$$

$$v _ { t } ^ { * } = & g _ { 1 } ( t ) ( x _ { t } - A ) + g _ { 0 } ( t ) \\ = & \frac { ( 1 + m _ { 0 } ^ { 2 } \theta ) \eta _ { 2 } - l _ { 3 } } { H } \cdot ( x _ { t } - A ) + \frac { l _ { 3 } } { H } \cdot ( R _ { t } - A ) + \frac { ( 1 + m _ { 0 } ^ { 2 } \theta ) \eta _ { 1 } } { 2 H } . \\$$

## A.4 Proof to Theorem 2

When m ( v ) = m 0 = 0 and β = 0 , d x t = -v t d t , according to Theorem 1, H = θη , l 3 = 0 , l 1 = θ 3 σ 2 η 2 , A 0 = 0 , and

$$b _ { 2 } ( t ) = \sqrt { \frac { \theta ^ { 3 } \sigma ^ { 2 } \eta } { 2 } } \cdot \coth \left ( \sqrt { \frac { \theta \sigma ^ { 2 } } { 2 \eta } } ( T - t ) \right ) .$$

Furthermore, b 1 solves the backward ODE

$$b _ { 1 } ^ { \prime } = \theta \mu + \frac { 1 } { H } b _ { 1 } b _ { 2 } + \theta ^ { 2 } \sigma ^ { 2 } ( R _ { t } - A ) , \ b _ { 1 } ( T ) = 0 .$$

Note that

$$\left ( b _ { 1 } \cdot \sinh \left ( \sqrt { \frac { \theta \sigma ^ { 2 } } { 2 \eta } } ( T - t ) \right ) \right ) ^ { \prime } & = \sinh \left ( \sqrt { \frac { \theta \sigma ^ { 2 } } { 2 \eta } } ( T - t ) \right ) \cdot b _ { 1 } ^ { \prime } - b _ { 1 } \cdot \sqrt { \frac { \theta \sigma ^ { 2 } } { 2 \eta } } \cdot \cosh \left ( \sqrt { \frac { \theta \sigma ^ { 2 } } { 2 \eta } } ( T - t ) \right ) \\ & = \sinh \left ( \sqrt { \frac { \theta \sigma ^ { 2 } } { 2 \eta } } ( T - t ) \right ) \cdot \left ( \theta \mu + \theta ^ { 2 } \sigma ^ { 2 } ( R _ { t } - A ) \right ) .$$

Integrate on both sides,

$$- b _ { 1 } ( t ) \cdot \sinh \left ( \sqrt { - \frac { \theta \sigma ^ { 2 } } { 2 } } ( T - t ) \right ) = & \int _ { t } ^ { T } \sinh \left ( \sqrt { \frac { \theta \sigma ^ { 2 } } { 2 \eta } } ( T - t ) \right ) \cdot ( \theta \mu + \theta ^ { 2 } \sigma ^ { 2 } ( R _ { s } - A ) \, d s . \\ & \Rightarrow b _ { 1 } ( t ) = - \, \frac { 1 } { \sinh \left ( \sqrt { \frac { \theta \sigma ^ { 2 } } { 2 \eta } } ( T - t ) \right ) } \cdot \int _ { t } ^ { T } \sinh \left ( \sqrt { \frac { \theta \sigma ^ { 2 } } { 2 \eta } } ( T - s ) \right ) \cdot ( \theta \mu + \theta ^ { 2 } \sigma ^ { 2 } ( R _ { s } - A ) \, d s .$$

Note that now hence,

$$\left ( \frac { x _ { t } - A } { \sinh \left ( \sqrt { \frac { \sigma ^ { 2 } } { 2 \eta } } ( T - t ) \right ) } \right ) ^ { \prime } = & \frac { ( x _ { t } - A ) ^ { \prime } \cdot \sinh \left ( \sqrt { \frac { \sigma ^ { 2 } } { 2 \eta } } ( T - t ) \right ) + ( x _ { t } - A ) \cdot \sqrt { \frac { \sigma ^ { 2 } } { 2 \eta } } \cdot \cosh \left ( \sqrt { \frac { \sigma ^ { 2 } } { 2 \eta } } ( T - t ) \right ) } { \sinh ^ { 2 } \left ( \sqrt { \frac { \sigma ^ { 2 } } { 2 \eta } } ( T - t ) \right ) } \\ = & \frac { T } { 2 H \sinh ^ { 2 } \left ( \sqrt { \frac { \sigma ^ { 2 } } { 2 \eta } } ( T - t ) \right ) } .$$

Integrate on both sides then integrate by parts, we have

$$\begin{array} { r l } & { \frac { x _ { t } - A } { \sinh \left ( \sqrt { \frac { \partial } { 2 n } } ( T - t ) \right ) } - \frac { x _ { 0 } - A } { \sinh \left ( \sqrt { \frac { \partial } { 2 n } } T \right ) } = \int _ { 0 } ^ { T } \frac { \sinh \left ( \sqrt { \frac { \partial } { 2 n } } ( T - u ) \right ) } { 2 H \sinh ^ { 2 } \left ( \sqrt { \frac { \partial } { 2 n } } ( T - s ) \right ) } \cdot ( \theta \mu + \theta ^ { 2 } \sigma ^ { 2 } ( R _ { u } - A ) \, d u s } \\ & { = \frac { 1 } { \sinh \left ( \sqrt { \frac { \partial } { 2 n } } T \right ) } \int _ { 0 } ^ { t } \frac { 1 } { \sqrt { 2 3 \sigma ^ { 2 } } \eta } \sinh \left ( \sqrt { \frac { \theta \sigma ^ { 2 } } { 2 n } } s \right ) \cdot ( \theta \mu + \theta ^ { 2 } \sigma ^ { 2 } ( R _ { s } - A ) \, d s + \frac { \sinh \left ( \sqrt { \frac { \partial } { 2 n } } t \right ) } { \sinh \left ( \sqrt { \frac { \partial } { 2 n } } T \right ) } \cdot \frac { 1 } { \sinh \left ( \sqrt { \frac { \partial } { 2 n } } ( T - t ) \right ) } } \\ & { \cdot \int _ { t } ^ { T } \frac { 1 } { \sqrt { 2 3 \sigma ^ { 2 } } \eta } \sinh \left ( \sqrt { \frac { \theta \sigma ^ { 2 } } { 2 \eta } } ( T - s ) \right ) \cdot ( \theta \mu + \theta ^ { 2 } \sigma ^ { 2 } ( R _ { s } - A ) \, d s } . } \end{array}$$

Denote we can solve that

$$x _ { t } = & \frac { \kappa } { \sinh \kappa T } \int _ { 0 } ^ { T } \left ( R _ { s } \sinh ( \kappa \min ( s , t ) ) \sinh ( \kappa ( T - \max ( s , t ) ) ) \right ) \text {d} s \\ & + \left ( x _ { 0 } - \frac { \mu } { \theta \sigma ^ { 2 } } \right ) \cdot \frac { \sinh \kappa ( T - t ) } { \sinh \kappa T } + A + \left ( - A + \frac { \mu } { \theta \sigma ^ { 2 } } \right ) \cdot \frac { \sinh \kappa T - \sinh \kappa t } { \sinh \kappa T } .$$

Furthermore,

$$x _ { t } = & \frac { \mu } { \theta \sigma ^ { 2 } } + \left ( x _ { 0 } - \frac { \mu } { \theta \sigma ^ { 2 } } \right ) \cdot \frac { \sinh \kappa ( T - t ) } { \sinh \kappa T } + \left ( A - \frac { \mu } { \theta \sigma ^ { 2 } } \right ) \cdot \frac { \sinh \kappa t } { \sinh \kappa T } \\ & + \frac { \sinh \kappa ( T - t ) } { \sinh \kappa T } \cdot \int _ { 0 } ^ { t } \kappa \sinh \kappa R _ { \ } d s + \frac { \sinh \kappa t } { \sinh \kappa T } \cdot \int _ { t } ^ { t } \kappa \sinh \kappa ( T - S ) R _ { \ } d s \\ = & \frac { \mu } { \theta \sigma ^ { 2 } } + \frac { \sinh \kappa ( T - t ) } { \sinh \kappa T } \cdot \left ( x _ { 0 } - \frac { \mu } { \theta \sigma ^ { 2 } } + \int _ { 0 } ^ { t } \kappa \sinh \kappa R _ { \ } d s \right ) + \frac { \sinh \kappa } { \sinh \kappa T } \cdot \left ( A - \frac { \mu } { \theta \sigma ^ { 2 } } + \int _ { t } ^ { T } \kappa \sinh \kappa ( T - s ) R _ { \ } d s \right )$$

$$\frac { \theta ^ { 2 } \sigma ^ { 2 } } { \sqrt { 2 \theta ^ { 3 } \sigma ^ { 2 } \eta } } = \sqrt { \frac { \theta \sigma ^ { 2 } } { 2 \eta } } = \colon \kappa ,$$

$$v _ { t } = - x _ { t } ^ { \prime } = - ( x _ { t } - A ) ^ { \prime } = \frac { b _ { 2 } } { H } ( x _ { t } - A ) + \frac { b _ { 1 } } { 2 H } ,$$

## A.5 Proof to Lemma 1

$$\begin{array} { r l } & { A . 5 } & { \text {Proof to Lemma } 1 } \\ & { \frac { \kappa } { \sinh \kappa T } \int _ { 0 } ^ { T } \left ( \sinh ( \kappa \min ( s , t ) ) \sinh ( \kappa ( T - \max ( s , t ) ) ) \right ) d s } \\ & { = \frac { \kappa } { \sinh \kappa T } \cdot \int _ { 0 } ^ { t } \sinh \kappa s d s \cdot \sinh ( \kappa ( T - t ) ) + \frac { \kappa } { \sinh \kappa T } \cdot \int _ { t } ^ { T } \sinh \kappa ( T - s ) d s \cdot \sinh \kappa t } \\ & { = \frac { \sinh ( \kappa ( T - t ) ) } { \sinh \kappa T } \cdot ( \cosh \kappa t - 1 ) + \frac { \sinh \kappa t } { \sinh \kappa T } \cdot ( \cosh \kappa ( T - t ) - 1 ) } \\ & { = \frac { \sinh \kappa T - \sinh \kappa t } { \sinh \kappa T } - \frac { \sinh \kappa ( T - t ) } { \sinh \kappa T } = T C _ { t } - I S _ { t } . } \end{array}$$

## A.6 Proof to Proposition 2

By Theorem 2 and Lemma 1,

$$x _ { t } = & \frac { \kappa } { \sinh \kappa T } , \int _ { 0 } ^ { T } \left ( R \sinh ( \kappa \min ( s , t ) ) \sinh ( \kappa ( T - \max ( s , t ) ) ) \right ) \cos \\ & + \left ( x _ { 0 } - \frac { \mu } { \theta \sigma ^ { 2 } } \right ) \cdot \frac { \sinh \kappa ( T - t ) } { \sinh \kappa T } + A + \left ( - A + \frac { \mu } { \theta \sigma ^ { 2 } } \right ) \cdot \frac { \sinh \kappa T - \sinh \kappa t } { \sinh \kappa T } \\ = & \left ( x _ { 0 } - \frac { \mu } { \theta \sigma ^ { 2 } } - R \right ) \cdot IS _ { t } + \left ( - A + \frac { \mu } { \theta \sigma ^ { 2 } } + R \right ) \cdot T C _ { t } + A .$$

## A.7 Proof to Proposition 3

Note that R + µ θσ 2 appears as a whole, so WLOG, we may assume that µ ≡ 0 . When the reference strategy is R , the optimal strategy is given by

$$x _ { t } = A + ( R - A ) \cdot \mathbb { T } C _ { t } + ( x _ { 0 } - R ) \cdot \mathbb { S } _ { t } ,$$

$$v _ { t } & = - x _ { t } ^ { \prime } = - \left ( R - A \right ) \cdot T C _ { t } ^ { \prime } - ( x _ { 0 } - R ) \cdot \mathbb { I } _ { t } ^ { \prime } \\ & = - \left ( R - A \right ) \cdot \frac { - \kappa \cosh \kappa t } { \sinh \kappa T } - ( x _ { 0 } - R ) \cdot \frac { - \kappa \cosh \kappa ( T - t ) } { \sinh \kappa T } ,$$

note that 0 ≤ t ≤ T , then cosh κt ≥ 0 and cosh κ ( T -t ) ≥ 0 , so when A ≤ R ≤ x 0 , v t ≥ 0 , which represents that the optimal strategy does not contain overshooting. Note that

$$x _ { t } ^ { \prime \prime } = - v _ { t } ^ { \prime } = ( R - A ) \cdot \frac { - \kappa ^ { 2 } \sinh \kappa t } { \sinh \kappa T } + ( x _ { 0 } - R ) \cdot \frac { \kappa ^ { 2 } \sinh \kappa ( T - t ) } { \sinh \kappa T } ,$$

so when R &gt; x 0 &gt; A , x ′′ t = -v ′ t ≤ 0 , which implies that the optimal strategy is a concave function, so

$$\min _ { 0 \leq t \leq T } v _ { t } & = v _ { 0 } = - ( R - A ) \cdot \frac { - \kappa } { \sinh \kappa T } - ( x _ { 0 } - R ) \cdot \frac { - \kappa \cosh \kappa T } { \sinh \kappa T } \\ & = \frac { \kappa } { \sinh \kappa T } \cdot [ ( 1 - \cosh \kappa T ) R + ( x _ { 0 } \cosh \kappa T - A ) ] \, ,$$

then

□

□

□

so when so when

$$R > \frac { x _ { 0 } \cosh \kappa T - A } { \cosh \kappa T - 1 } = x _ { 0 } + \frac { 1 } { \cosh \kappa T - 1 } \cdot ( x _ { 0 } - A ) ,$$

the optimal strategy contains overshooting, and when x 0 &lt; R ≤ x 0 + 1 cosh κT -1 · ( x 0 -A ) , the optimal strategy does not contains overshooting. Similarly, when R &lt; A &lt; x 0 , q ′′ t = -v ′ t ≥ 0 , which implies that the optimal strategy is a convex function, so

$$\min _ { 0 \leq t \leq T } v _ { t } & = v _ { T } = - ( R - A ) \cdot \frac { - \kappa \cosh \kappa T } { \sinh \kappa T } - ( x _ { 0 } - R ) \cdot \frac { - \kappa } { \sinh \kappa T } \\ & = \frac { \kappa } { \sinh \kappa T } \cdot [ ( \cosh \kappa T - 1 ) R - ( x _ { 0 } - A \cosh \kappa T ) ] \, ,$$

$$R < \frac { A \cosh \kappa T - x _ { 0 } } { \cosh \kappa T - 1 } = A - \frac { 1 } { \cosh \kappa T - 1 } \cdot ( x _ { 0 } - A ) ,$$

the optimal strategy contains overshooting.

## A.8 Proof to Proposition 4

By the results given in Theorem 2, the optimal strategy is a deterministic one. In other words, when µ = m 0 = 0 ,

$$\sup _ { v \in \mathcal { A } } \mathbb { E } \left [ u \left ( \tilde { \Pi } \right ) \right ] = \sup _ { v \in \mathcal { A } _ { d e t } } \mathbb { E } \left [ u \left ( \tilde { \Pi } \right ) \right ] ,$$

where A det = { v ∈ A : v is deterministic } . When v ∈ A det , x t = x 0 -∫ t 0 v s d s is also deterministic, hence,

$$\mathbb { E } \left [ u \left ( \tilde { \Pi } \right ) \right ] & = \mathbb { E } \left [ \frac { 1 } { 6 } \left ( 1 - \exp \left \{ \theta \beta ( x _ { T } - A ) ^ { 2 } - \int _ { 0 } ^ { T } \theta \left ( - \eta v _ { t } ^ { 2 } - \gamma v _ { t } ( x _ { t } - A ) \right ) d t - \int _ { 0 } ^ { T } \theta \sigma ( x _ { t } - R _ { t } ) d W _ { t } \right \} \right ) \right ] \\ & = \frac { 1 } { \theta } - \frac { 1 } { \theta } \cdot \exp \left \{ \theta \beta ( x _ { T } - A ) ^ { 2 } - \int _ { 0 } ^ { T } \left [ \theta \left ( - \eta v _ { t } ^ { 2 } - \gamma v _ { t } ( x _ { t } - A ) \right ) - \frac { 1 } { 2 } \theta ^ { 2 } \sigma ^ { 2 } ( x _ { t } - R _ { t } ) ^ { 2 } \right ] d t \right \} .$$

Subject to x T = A (or β → + ∞ ) , ∫ T 0 v t ( x t -A )d t = 1 2 ( x 0 -A ) 2 is a constant, hence, maximizing the expected utility is equivalent to a typical variational problem

$$\begin{cases} \inf _ { v \in \mathcal { A } _ { d e t } } \int _ { 0 } ^ { T } \left [ \eta v _ { t } ^ { 2 } + \frac { \theta \sigma ^ { 2 } } { 2 } ( x _ { t } - R _ { t } ) ^ { 2 } \right ] d t \\ \quad s . t . \ x _ { t } = x _ { 0 } - \int _ { 0 } ^ { t } v _ { s } d s , \ x _ { T } = A , \end{cases}$$

Note that the objective can be divided into n parts, each with a constant RS:

$$\int _ { 0 } ^ { T } \left ( \eta v _ { t } ^ { 2 } + \frac { \gamma } { 2 } \sigma ^ { 2 } ( x _ { t } - R _ { t } ) ^ { 2 } \right ) d t = \sum _ { k = 1 } ^ { n } \int _ { \frac { ( k - 1 ) T } { n } } ^ { \frac { k T } { n } } \left ( \eta v _ { t } ^ { 2 } + \frac { \gamma } { 2 } \sigma ^ { 2 } \left ( x _ { t } - R ^ { ( k ) } \right ) ^ { 2 } \right ) d t .$$

We divide the optimization problem into three steps:

- Find the optimal value of x ∗ kT n , 1 ≤ k ≤ n -1 . We can directly use Theorem 2: suppose the optimal

□

strategy is x ∗ t , note that µ = 0 ,

$$x _ { t } ^ { * } = & \frac { \kappa } { \sinh \kappa T } \int _ { 0 } ^ { T } \left ( R _ { s } \sinh ( \kappa \min ( s , t ) ) \sinh ( \kappa ( T - \max ( s , t ) ) ) \right ) d s \\ & + x _ { 0 } \cdot \frac { \sinh \kappa ( T - t ) } { \sinh \kappa T } + A - A \cdot \frac { \sinh \kappa T - \sinh \kappa t } { \sinh \kappa T } ,$$

where R is the given piece-wise constant RS. For 1 ≤ k ≤ n -1 ,

$$where R is the given piece-wise constant RS. For 1 \leq k \leq n - 1 , \\ \times _ { k \mathbb { T } } ^ { \ast } = & \sinh \kappa ( T - \frac { k T } { n } ) + A \cdot \frac { \sinh \kappa \frac { k T } { n } } { \sinh \kappa T } + \frac { \sinh \kappa \left ( T - \frac { k T } { n } \right ) } { \sinh \kappa T } \cdot \sum _ { i = 1 } ^ { k } R ^ { ( i ) } \cdot \int _ { ( i - 1 ) T } ^ { \frac { k T } { n } } \sinh \kappa T \\ & + \frac { \sinh \kappa \frac { k T } { n } } { \sinh \kappa T } \cdot \sum _ { i = k + 1 } ^ { n } R ^ { ( i ) } \cdot \int _ { ( i - 1 ) T } ^ { \frac { k T } { n } } \sinh \left ( \kappa ( T - s ) \right ) d s \\ = & \sinh \kappa ( T - \frac { k T } { n } ) + A \cdot \frac { \sinh \kappa \frac { k T } { n } } { \sinh \kappa T } \\ & + \frac { \sinh \kappa ( T - \frac { k T } { n } ) } { \sinh \kappa T } \cdot \sum _ { i = 1 } ^ { k } R ^ { ( i ) } \cdot \left ( \cosh \left ( \kappa \frac { i T } { n } \right ) - \cosh \left ( \kappa \frac { ( i - 1 ) T } { n } \right ) \right ) \\ & + \frac { \sinh \kappa \frac { k T } { n } } { \sinh \kappa T } \cdot \sum _ { i = k + 1 } ^ { n } R ^ { ( i ) } \cdot \left ( \cosh \left ( \kappa \frac { ( n - i + 1 ) T } { n } \right ) - \cosh \left ( \kappa \frac { ( n - i ) T } { n } \right ) \right ) . \\ \\ \text {Denote } R ^ { ( 0 ) } \colon = & \, x _ { 0 } , R ^ { ( n + 1 ) } \colon = A , \, \text {and}$$

Denote R (0) := x 0 , R ( n +1) := A , and

$$b _ { i } = \begin{cases} 1 , & i = 0 , \\ \cosh \left ( \kappa \frac { i T } { n } \right ) - \cosh \left ( \kappa \frac { ( i - 1 ) T } { n } \right ) , & 1 \leq i \leq n - 1 , \end{cases}$$

we can rewrite

$$x _ { \frac { k T } { n } } ^ { * } = \frac { \sinh \zeta ( T - \frac { k T } { n } ) } { \sinh \kappa T } \cdot \sum _ { i = 0 } ^ { k } b _ { i } R ^ { ( i ) } + \frac { \sinh \kappa \frac { k T } { n } } { \sinh \kappa T } \cdot \sum _ { i = k + 1 } ^ { n + 1 } b _ { n - i + 1 } R ^ { ( i ) } , \ 1 \leq k \leq n - 1 .$$

Furthermore, we denote the optimal values a k := x ∗ kT n , 1 ≤ k ≤ n -1 . Note that the sum of coefficients in a k is

$$\frac { \sinh \kappa \left ( T - \frac { k T } { n } \right ) } { \sinh \kappa T } \cdot \sum _ { i = 0 } ^ { k } b _ { i } + \frac { \sinh \kappa \frac { k T } { n } } { \sinh \kappa T } \cdot \sum _ { i = k + 1 } ^ { n + 1 } b _ { n - i + 1 } \\ = & \frac { \sinh \kappa \left ( T - \frac { k T } { n } \right ) } { \sinh \kappa T } \cdot \cosh \kappa \frac { k T } { n } + \frac { \sinh \kappa \frac { k T } { n } } { \sinh \kappa T } \cdot \cosh \kappa \frac { ( n - k ) T } { n } = 1 ,$$

so a k is a weighted average of R ( i ) 's.

- Note that we already know the value of optimal strategy x kT n , so the optimization problem is equivalent to the following optimization problem with extra constraints:

$$\inf _ { \substack { v \in A _ { \det } \\ s . t . \ x _ { t } = x _ { 0 } - \int _ { 0 } ^ { T } v _ { s } d s , \ x _ { T } = A , \\ x _ { \frac { k T } { n } } = a _ { k } , \ 1 \leq k \leq n - 1 . } } \frac { t } { n } \inf _ { \substack { v \in A _ { \det } \\ v _ { s } = 1 } } \sum _ { \substack { ( \frac { k T } { n } - 1 ) T } } ^ { n } \int _ { \frac { k T } { n } } ^ { \frac { k T } { n } } \left ( \eta v _ { t } ^ { 2 } + \frac { \gamma } { 2 } \sigma ^ { 2 } \left ( x _ { t } - R ^ { ( k ) } \right ) ^ { 2 } \right ) \\ \intertext { f o r } x _ { t } = x _ { 0 } - \int _ { 0 } ^ { T } v _ { s } d s , \ x _ { T } = A , \\ x _ { \frac { k T } { n } } = a _ { k } , \ 1 \leq k \leq n - 1 . }$$

Denote a 0 = x 0 and a n = A , inheriting from the spirit of dynamic programming, we can further divide the optimization problem into n parts: for 1 ≤ k ≤ n , where the k -th sub-problem is given by

$$\begin{cases} \inf _ { v \in \mathcal { A } _ { \det } } \int _ { \Omega _ { n } ^ { T } } ^ { \frac { k _ { T } } { n } } \left ( \eta v _ { t } ^ { 2 } + \frac { \theta \sigma ^ { 2 } } { 2 } \left ( x _ { t } - R ^ { ( k ) } \right ) ^ { 2 } \right ) \mathrm d t \\ s . t . \ x _ { t } = a _ { k - 1 } - \int _ { \frac { ( k - 1 ) T } { n } } ^ { t } v _ { \ } d s , \, \frac { ( k - 1 ) T } { n } \leq t \leq \frac { k T } { n } , \, x _ { \frac { k T } { n } } = a _ { k } , \end{cases}$$

which is a constant RS problem with time period [ ( k -1) T n , kT n ] , of which the optimal strategy is given by

$$x _ { t } ^ { ( k ) } = a _ { k } + \left ( R ^ { ( k ) } - a _ { k } \right ) \, \text {TC} _ { t - \frac { ( k - 1 ) T } { n } } + \left ( a _ { k - 1 } - R ^ { ( k ) } \right ) \, \text {IS} _ { t - \frac { ( k - 1 ) T } { n } } , \frac { ( k - 1 ) T } { n } \leq t \leq \frac { k T } { n } ,$$

where κ := √ θσ 2 2 η and

$$IS _ { t } \coloneqq \frac { \sinh \kappa \left ( \frac { T } { n } - t \right ) } { \sinh \kappa \frac { T } { n } } , \ \ T C _ { t } \coloneqq \frac { \sinh \kappa \frac { T } { n } - \sinh \kappa t } { \sinh \kappa \frac { T } { n } } .$$

- Connect n optimal strategies to obtain the optimal strategy of the original optimization problem. Denote

$$x _ { t } ^ { * * } = \sum _ { k = 1 } ^ { n } x _ { t } ^ { ( k ) } \, \mathbb { 1 } _ { \{ \frac { ( k - 1 ) T } { n } \leq t < \frac { k T } { n } \} } + A \, \mathbb { 1 } _ { \{ t = T \} } ,$$

then by the results of constant reference strategies, for any strategy x t ,

$$\int _ { 0 } ^ { T } \left [ \eta v _ { t } ^ { 2 } + \frac { \theta \sigma ^ { 2 } } { 2 } ( x _ { t } - R _ { t } ) ^ { 2 } \right ] d t & = \sum _ { k = 1 } ^ { n } \int _ { \frac { ( k - n ) T } { n } } ^ { \frac { K T } { n } T } \left ( \eta v _ { t } ^ { 2 } + \frac { \gamma } { 2 } \sigma ^ { 2 } \left ( x _ { t } - R ^ { ( k ) } \right ) ^ { 2 } \right ) \\ & \geq \sum _ { k = 1 } ^ { n } \int _ { \frac { ( k - n ) T } { n } } ^ { \frac { K T } { n } T } \left ( \eta \left ( - x _ { t } ^ { ( k ) } \right ) ^ { 2 } + \frac { \gamma } { 2 } \sigma ^ { 2 } \left ( x _ { t } ^ { ( k ) } - R ^ { ( k ) } \right ) ^ { 2 } \right ) \\ & = \int _ { 0 } ^ { T } \left [ \eta ( - \dot { x } _ { t } ^ { * * } ) ^ { 2 } + \frac { \theta \sigma ^ { 2 } } { 2 } ( x _ { t } ^ { * * } - R _ { t } ) ^ { 2 } \right ] d t ,$$

where implies that the optimal value is obtained when x t = x ∗∗ t , in other words, x ∗∗ t is the optimal strategy.

□

## A.9 Proof to Theorem 3

According to Theorem 2, the optimal strategies x t and ˜ x t can be given by

$$x _ { t } = & \frac { \kappa } { \sinh \kappa T } \int _ { 0 } ^ { T } \left ( R _ { s } \sinh ( \kappa \min ( s , t ) ) \sinh ( \kappa ( T - \max ( s , t ) ) ) \right ) \text {d} s \\ & + \left ( x _ { 0 } - \frac { \mu } { \theta \sigma ^ { 2 } } \right ) \cdot \frac { \sinh \kappa ( T - t ) } { \sinh \kappa T } + A + \left ( - A + \frac { \mu } { \theta \sigma ^ { 2 } } \right ) \cdot \frac { \sinh \kappa T - \sinh \kappa t } { \sinh \kappa T } ,$$

and

$$\tilde { x } _ { t } = & \frac { \kappa } { \sinh \kappa T } \int _ { 0 } ^ { T } \left ( \tilde { R } _ { t } \sinh ( \kappa \min ( s , t ) ) \sinh ( \kappa ( T - \max ( s , t ) ) ) \right ) \text {d} s \\ & + \left ( x _ { 0 } - \frac { \mu } { \theta \sigma ^ { 2 } } \right ) \cdot \frac { \sinh \kappa ( T - t ) } { \sinh \kappa T } + A + \left ( - A + \frac { \mu } { \theta \sigma ^ { 2 } } \right ) \cdot \frac { \sinh \kappa T - \sinh \kappa t } { \sinh \kappa T } ,$$

where x t , ˜ x t are the optimal strategy with respect to reference strategies R t and ˜ R t respectively. Hence, by Jensen's inequality,

$$\text {Jensin's frequency} ; \\ ( x _ { t } - \widetilde { x } _ { t } ) ^ { 2 } = & \frac { \kappa ^ { 2 } } { \sinh ^ { 2 } \kappa T } \left ( \int _ { 0 } ^ { T } \left ( \left ( R _ { s } ^ { ( 1 ) } - R _ { s } ^ { ( 2 ) } \right ) \sinh ( \kappa \min ( s , t ) ) \sinh ( \kappa ( T - \max ( s , t ) ) ) \right ) \text {d} s \right ) ^ { 2 } \\ \leq & \frac { \kappa ^ { 2 } } { \sinh ^ { 2 } \kappa T } \int _ { 0 } ^ { T } \left ( R _ { s } ^ { ( 1 ) } - R _ { s } ^ { ( 2 ) } \right ) ^ { 2 } \text {d} s \cdot \int _ { 0 } ^ { T } \sinh ^ { 2 } ( \kappa \min ( s , t ) ) \sinh ^ { 2 } ( \kappa ( T - \max ( s , t ) ) ) \text {d} s \\ < & \frac { \kappa ^ { 2 } } { \sinh ^ { 2 } \kappa T } \cdot \varepsilon \cdot \frac { 1 } { 4 \kappa } \left ( \sinh ^ { 2 } ( \kappa t ) \left ( \sinh ( 2 \kappa ( T - t ) ) - 2 \kappa ( T - t ) \right ) + \sinh ^ { 2 } ( \kappa ( T - t ) ) \left ( \sinh ( 2 \kappa t ) - 2 \kappa t \right ) \right ) \\ \leq & \frac { \kappa ^ { 2 } } { \sinh ^ { 2 } \kappa T } \cdot \varepsilon \cdot \frac { 1 } { 2 \kappa } \sinh ^ { 2 } \left ( \kappa \frac { T } { 2 } \right ) \left ( \sinh \kappa T - \kappa T \right ) = \frac { \kappa \left ( \sinh \kappa T - \kappa T \right ) } { 4 \left ( \cosh \kappa T + 1 \right ) } \cdot \varepsilon < \frac { \kappa } { 4 } \\ \text {which implies the fact that when } \varepsilon \geq 0 \ \widetilde { \kappa } \to \kappa \text {, } \text {so} \text {wey may use the outimal strategy by a device-wise constant}$$

which implies the fact that when ε → 0 , ˜ x t → x t . So we may use the optimal strategy by a piece-wise constant RS to approximate the general RS, with small error

$$| x _ { t } - \widetilde { x } _ { t } | < \frac { 1 } { 2 } \sqrt { \kappa \varepsilon } .$$

## References

- [1] R. Almgren and N. Chriss, 'Optimal execution of portfolio transactions,' Journal of Risk , vol. 3, pp. 5-40, 2001.
- [2] C. Institute, CFA Program Curriculum 2018 Level II . John Wiley &amp; Sons, 2017.
- [3] O. Guéant, 'Target close execution strategies.' [Online]. Available: https://www.oliviergueant.com/ uploads/4/3/0/9/4309511/targetclose.pdf
- [4] R. Almgren and N. Chriss, 'Value under liquidation,' Risk , vol. 12, no. 12, pp. 61-63, 1999.
- [5] R. F. Almgren, 'Optimal execution with nonlinear impact functions and trading-enhanced risk,' Applied Mathematical Finance , vol. 10, no. 1, pp. 1-18, 2003.
- [6] D. Bertsimas and A. W. Lo, 'Optimal control of execution costs,' Journal of Financial Markets , vol. 1, no. 1, pp. 1-50, 1998.
- [7] J. Gatheral, 'No-dynamic-arbitrage and market impact,' Quantitative finance , vol. 10, no. 7, pp. 749-759, 2010.
- [8] J. Gatheral, A. Schied, and A. Slynko, 'Transient linear price impact and fredholm integral equations,' Mathematical Finance: An International Journal of Mathematics, Statistics and Financial Economics , vol. 22, no. 3, pp. 445-474, 2012.
- [9] S. Tse, P. Forsyth, J. Kennedy, and H. Windcliff, 'Comparison between the mean-variance optimal and the mean-quadratic-variation optimal trading strategies,' Applied Mathematical Finance , vol. 20, no. 5, pp. 415-449, 2013.
- [10] X. Cheng, M. Di Giacinto, and T.-H. Wang, 'Optimal execution with dynamic risk adjustment,' Journal of the Operational Research Society , vol. 70, no. 10, pp. 1662-1677, 2019.
- [11] C. Frei and N. Westray, 'Optimal execution of a vwap order: a stochastic control approach,' Mathematical Finance , vol. 25, no. 3, pp. 612-639, 2015.
- [12] Á. Cartea and S. Jaimungal, 'A closed-form execution strategy to target volume weighted average price,' SIAM Journal on Financial Mathematics , vol. 7, no. 1, pp. 760-785, 2016.
- [13] O. Guéant and G. Royer, 'Vwap execution and guaranteed vwap,' SIAM Journal on Financial Mathematics , vol. 5, no. 1, pp. 445-471, 2014.
- [14] R. Almgren and J. Lorenz, 'Adaptive arrival price,' Trading , vol. 2007, no. 1, pp. 59-66, 2007.
- [15] C. Frei and N. Westray, 'Optimal execution in hong kong given a market-on-close benchmark,' Quantitative Finance , vol. 18, no. 4, pp. 655-671, 2018.
- [16] O. Guéant, J. Pu, and G. Royer, 'Accelerated share repurchase: pricing and execution strategy,' International Journal of Theoretical and Applied Finance , vol. 18, no. 03, p. 1550019, 2015.

- [17] L. Bargeron, M. Kulchania, and S. Thomas, 'Accelerated share repurchases,' Journal of Financial Economics , vol. 101, no. 1, pp. 69-89, 2011.
- [18] X. Cheng, M. Di Giacinto, and T.-H. Wang, 'Optimal execution with uncertain order fills in almgrenchriss framework,' Quantitative Finance , vol. 17, no. 1, pp. 55-69, 2017.
- [19] R. Carmona and L. Leal, 'Optimal execution with quadratic variation inventories,' SIAM Journal on Financial Mathematics , vol. 14, no. 3, pp. 751-776, 2023.
- [20] M. Nutz, K. Webster, and L. Zhao, 'Unwinding stochastic order flow: When to warehouse trades,' arXiv preprint arXiv:2310.14144 , 2023.
- [21] Á. Cartea and L. Sánchez-Betancourt, 'Brokers and informed traders: dealing with toxic flow and extracting trading signals,' Available at SSRN 4265814 , 2022.
- [22] J. Yong and X. Y. Zhou, Stochastic controls: Hamiltonian systems and HJB equations . Springer Science &amp; Business Media, 2012, vol. 43.
- [23] T. E. Duncan, 'Linear-exponential-quadratic gaussian control,' IEEE Transactions on Automatic Control , vol. 58, no. 11, pp. 2910-2911, 2013.
- [24] A. E. Lim and X. Y. Zhou, 'A new risk-sensitive maximum principle,' IEEE transactions on automatic control , vol. 50, no. 7, pp. 958-966, 2005.
- [25] R. Carmona and K. Webster, 'The self-financing equation in limit order book markets,' Finance and Stochastics , vol. 23, no. 3, pp. 729-759, Jul. 2019.
- [26] A. Mazzolo, 'Constraint Ornstein-Uhlenbeck bridges,' Journal of Mathematical Physics , vol. 58, no. 9, p. 093302, 09 2017.
- [27] O. Guéant, The Financial Mathematics of Market Liquidity: From optimal execution to market making . CRC Press, 2016, vol. 33.
- [28] R. C. Merton, 'Optimum consumption and portfolio rules in a continuous-time model,' in Stochastic optimization models in finance . Elsevier, 1975, pp. 621-661.