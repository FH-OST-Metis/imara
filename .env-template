MLFLOW_BACKEND_STORE_URI=postgresql://postgres:[DB_PASSWORD]@db.hjijyloqvddflojzrvcn.supabase.co:5432/postgres
MLFLOW_DEFAULT_ARTIFACT_ROOT=s3://Imara/
MLFLOW_HOST=127.0.0.1
MLFLOW_PORT=5002

AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_DEFAULT_REGION=eu-north-1
MLFLOW_S3_ENDPOINT_URL=https://hjijyloqvddflojzrvcn.storage.supabase.co/storage/v1/s3

GEMINI_API_KEY=
OPENAI_API_KEY=ollama

# Ollama Configuration (non-secret, local development)
# For local Docker development, use host.docker.internal to access Ollama from Supabase Edge Functions
OLLAMA_BASE_URL=http://host.docker.internal:11434/v1
OLLAMA_MODEL=bge-m3:567m  # BGE-M3 outputs 1024 dimensions (vs OpenAI's 1536)
OLLAMA_API_KEY=ollama  # Required by OpenAI client library, but unused by Ollama
